{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e307c075",
   "metadata": {},
   "source": [
    "# Práctica Classical Neuronal Networks\n",
    "\n",
    "* Alejandro Mayorga\n",
    "* Fernando Mondragón\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1521cbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Primer paso: Cargar la database y distribuir las imágenes de entrenamiento y evaluación\n",
    "\n",
    "from tensorflow . keras . datasets import fashion_mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "( x_train , y_train ), ( x_test , y_test ) = fashion_mnist . load_data ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9cf58c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Primeramente, tenemos que preparar los datos de forma que sean fácilmente introducibles en nuestra red. Esto\n",
    "#implica reorganizar el array original en el que se nos es dada la información, así como para su tipo de datos a\n",
    "#float\n",
    "\n",
    "train_images = x_train.reshape((60000, 28 * 28))\n",
    "test_images = x_test.reshape((10000, 28 * 28))\n",
    "\n",
    "train_images = train_images.astype('float32') / 255\n",
    "test_images = test_images.astype('float32') / 255\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ed81913",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos un tercer grupo de validación\n",
    "\n",
    "validation_images = train_images[:10000] # Copy of x_train from the begining (0) to 9999\n",
    "validation_labels = y_train[:10000]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_images = train_images[10000:] # Copy of x_train from 10000 to the end\n",
    "train_labels = y_train[10000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5339621c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Realizamos one-hot enconding para así disponer las etiquetas de forma que la red pueda entrenar\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "validation_labels = to_categorical(validation_labels)\n",
    "test_labels = to_categorical(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b22c1240",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opciones a probar\n",
    "\n",
    "epoch_n = [10,30]\n",
    "batch_size_n = [32,512]\n",
    "\n",
    "layers_n = [1,2]\n",
    "neurons_n = [16,64,128]\n",
    "learning_rates = [0.1,0.01,0.001]\n",
    "optimizers = [\"rmsprop\",\"Adam\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd274fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 50000\n",
      "\n",
      "counter: 1\n",
      "50000 50000\n",
      "\n",
      "counter: 2\n",
      "50000 50000\n",
      "\n",
      "counter: 3\n",
      "50000 50000\n",
      "\n",
      "counter: 4\n",
      "50000 50000\n",
      "\n",
      "counter: 5\n",
      "50000 50000\n",
      "\n",
      "counter: 6\n",
      "50000 50000\n",
      "\n",
      "counter: 7\n",
      "50000 50000\n",
      "\n",
      "counter: 8\n",
      "50000 50000\n",
      "\n",
      "counter: 9\n",
      "50000 50000\n",
      "\n",
      "counter: 10\n",
      "50000 50000\n",
      "\n",
      "counter: 11\n",
      "50000 50000\n",
      "\n",
      "counter: 12\n",
      "50000 50000\n",
      "\n",
      "counter: 13\n",
      "50000 50000\n",
      "\n",
      "counter: 14\n",
      "50000 50000\n",
      "\n",
      "counter: 15\n",
      "50000 50000\n",
      "\n",
      "counter: 16\n",
      "50000 50000\n",
      "\n",
      "counter: 17\n",
      "50000 50000\n",
      "\n",
      "counter: 18\n",
      "[0.8952999711036682, \"epoch: 30\\n batch: 32\\n layers: <module 'keras.api._v2.keras.layers' from 'C:\\\\\\\\Users\\\\\\\\odnan\\\\\\\\anaconda3\\\\\\\\envs\\\\\\\\MC2\\\\\\\\Lib\\\\\\\\site-packages\\\\\\\\keras\\\\\\\\api\\\\\\\\_v2\\\\\\\\keras\\\\\\\\layers\\\\\\\\__init__.py'>\\n neurons: 128\"]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#Ahora loopeamos por los hiperparametros\n",
    "#2*2*2*3*3*2 = 144 modelos. Aproximadamente 15s por modelo, aprox 40 min para probar todos\n",
    "counter = 0\n",
    "result = [(0,\"\")]\n",
    "for epoch in epoch_n: #\n",
    "    for batch in batch_size_n:#\n",
    "        for capas in layers_n: # \n",
    "            for neurons in neurons_n: #\n",
    "                for learning_r in learning_rates:\n",
    "                    for optimizador in optimizers: #\n",
    "                        model = keras.Sequential()\n",
    "\n",
    "                        model.add(layers.Input(shape=(784, )))\n",
    "                        for i in range(capas):\n",
    "                            model.add(layers.Dense(neurons, activation=\"relu\"))\n",
    "\n",
    "                        model.add(layers.Dense(10, activation=\"softmax\"))\n",
    "                        \n",
    "                        if optimizador ==\"rmsprop\":\n",
    "                            opt = keras.optimizers.RMSprop(learning_rate=learning_r)\n",
    "                        if optimizador ==\"Adam\":\n",
    "                            opt = keras.optimizers.Adam(learning_rate=learning_r)\n",
    "                        \n",
    "                        model.compile(optimizer=opt, \n",
    "                                  loss=\"categorical_crossentropy\",\n",
    "                                  metrics=[\"accuracy\"])\n",
    "\n",
    "                        print(len(train_images), len(train_labels))\n",
    "                        history =model.fit(train_images, train_labels, epochs=epoch,verbose=0, batch_size=batch, \n",
    "                            validation_data = (validation_images, validation_labels))\n",
    "                        \n",
    "                        history_dict = history.history\n",
    "                        result_val = max(history_dict['val_accuracy'])\n",
    "                        print()\n",
    "                        \n",
    "#Guardamos todos los modelos  if result[0]< result_val:\n",
    "                        result=[result.append((result_val,\"epoch: \"+ str(epoch)+ \"\\n batch: \" +str(batch)+ \"\\n layers: \" +str(layers)+ \"\\n neurons: \" +str(neurons)))]#+ \"\\n learning rate: \" +str(learning rate) +\" optimizador: \" +optimizador]                      \n",
    "                        counter +=1\n",
    "                        print(\"counter:\",counter)\n",
    "print(result)          \n",
    "\n",
    "#[0.8952999711036682, \"epoch: 30\\n batch: 32\\n layers: <module 'keras.api._v2.keras.layers' from 'C:\\\\\\\\Users\\\\\\\\odnan\\\\\\\\anaconda3\\\\\\\\envs\\\\\\\\MC2\\\\\\\\Lib\\\\\\\\site-packages\\\\\\\\keras\\\\\\\\api\\\\\\\\_v2\\\\\\\\keras\\\\\\\\layers\\\\\\\\__init__.py'>\\n neurons: 128\"]\n",
    "\n",
    "#TODO se podía hacer una gráfica con los resultados de cada evaluación\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e91c4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ahora ejecutamos el modelo sobre los datos de test para ver su accuracy real\n",
    "\n",
    "#TODO Definir el modelo que mejor resultado de y reentrenarlo\n",
    "\n",
    "results = model.evaluate(x_test, y_test)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d918b8",
   "metadata": {},
   "source": [
    "# REGULARIZACIÓN\n",
    "Ahora vamos a probar algunos de los modelos anteriores utilizando las técnicas de regularización de \"dropout\" y \"batch normalization\" para tratar de obtener mejores resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7269ada1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropout\n",
    "\n",
    "#Definir modelo y para implementar el dropout, añadir las capas de Dropout\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "#Ejecutar 3 o 4 modelos entre los que esté el mejor obtenido anteriormente"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593dbe0e",
   "metadata": {},
   "source": [
    "### Resultados del dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747da55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch normalization\n",
    "\n",
    "#Similarmente al caso anterior, implementamos la batch regularization añadiendo capas intermedias de regularización\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()\n",
    "#Ejecutar 3 o 4 modelos entre los que esté el mejor obtenido anteriormente"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9d4a02",
   "metadata": {},
   "source": [
    "### Resultados de la batch normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55d58624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 50000\n",
      "Epoch 1/10\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.5897 - accuracy: 0.7936 - val_loss: 0.4734 - val_accuracy: 0.8315\n",
      "Epoch 2/10\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.4027 - accuracy: 0.8532 - val_loss: 0.3772 - val_accuracy: 0.8626\n",
      "Epoch 3/10\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.3525 - accuracy: 0.8720 - val_loss: 0.3336 - val_accuracy: 0.8798\n",
      "Epoch 4/10\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.3252 - accuracy: 0.8807 - val_loss: 0.3815 - val_accuracy: 0.8641\n",
      "Epoch 5/10\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.3027 - accuracy: 0.8870 - val_loss: 0.3161 - val_accuracy: 0.8824\n",
      "Epoch 6/10\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.2848 - accuracy: 0.8940 - val_loss: 0.3049 - val_accuracy: 0.8936\n",
      "Epoch 7/10\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.2728 - accuracy: 0.8985 - val_loss: 0.3161 - val_accuracy: 0.8820\n",
      "Epoch 8/10\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.2587 - accuracy: 0.9038 - val_loss: 0.3469 - val_accuracy: 0.8691\n",
      "Epoch 9/10\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.2481 - accuracy: 0.9077 - val_loss: 0.3206 - val_accuracy: 0.8859\n",
      "Epoch 10/10\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.2387 - accuracy: 0.9102 - val_loss: 0.3117 - val_accuracy: 0.8921\n",
      "50000 50000\n",
      "Epoch 1/10\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.2330 - accuracy: 0.9127 - val_loss: 0.3065 - val_accuracy: 0.8936\n",
      "Epoch 2/10\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.2218 - accuracy: 0.9175 - val_loss: 0.3218 - val_accuracy: 0.8881\n",
      "Epoch 3/10\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.2134 - accuracy: 0.9208 - val_loss: 0.3110 - val_accuracy: 0.8970\n",
      "Epoch 4/10\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.2049 - accuracy: 0.9239 - val_loss: 0.3266 - val_accuracy: 0.8825\n",
      "Epoch 5/10\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.2015 - accuracy: 0.9249 - val_loss: 0.3295 - val_accuracy: 0.8814\n",
      "Epoch 6/10\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.1933 - accuracy: 0.9281 - val_loss: 0.3220 - val_accuracy: 0.8940\n",
      "Epoch 7/10\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.1879 - accuracy: 0.9307 - val_loss: 0.3508 - val_accuracy: 0.8890\n",
      "Epoch 8/10\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.1821 - accuracy: 0.9334 - val_loss: 0.3084 - val_accuracy: 0.8991\n",
      "Epoch 9/10\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.1754 - accuracy: 0.9359 - val_loss: 0.3570 - val_accuracy: 0.8847\n",
      "Epoch 10/10\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.1709 - accuracy: 0.9378 - val_loss: 0.3488 - val_accuracy: 0.8920\n",
      "50000 50000\n",
      "Epoch 1/10\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.1692 - accuracy: 0.9378 - val_loss: 0.3347 - val_accuracy: 0.8973\n",
      "Epoch 2/10\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.1605 - accuracy: 0.9410 - val_loss: 0.3421 - val_accuracy: 0.8938\n",
      "Epoch 3/10\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.1574 - accuracy: 0.9425 - val_loss: 0.3660 - val_accuracy: 0.8954\n",
      "Epoch 4/10\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.1534 - accuracy: 0.9436 - val_loss: 0.3443 - val_accuracy: 0.8950\n",
      "Epoch 5/10\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.1482 - accuracy: 0.9453 - val_loss: 0.3406 - val_accuracy: 0.8981\n",
      "Epoch 6/10\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.1450 - accuracy: 0.9468 - val_loss: 0.3777 - val_accuracy: 0.8896\n",
      "Epoch 7/10\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.1425 - accuracy: 0.9473 - val_loss: 0.3598 - val_accuracy: 0.8981\n",
      "Epoch 8/10\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.1388 - accuracy: 0.9492 - val_loss: 0.3978 - val_accuracy: 0.8921\n",
      "Epoch 9/10\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.1361 - accuracy: 0.9501 - val_loss: 0.3685 - val_accuracy: 0.8973\n",
      "Epoch 10/10\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.1301 - accuracy: 0.9531 - val_loss: 0.4261 - val_accuracy: 0.8854\n",
      "50000 50000\n",
      "Epoch 1/10\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.1323 - accuracy: 0.9519 - val_loss: 0.3747 - val_accuracy: 0.8965\n",
      "Epoch 2/10\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.1262 - accuracy: 0.9540 - val_loss: 0.3742 - val_accuracy: 0.8928\n",
      "Epoch 3/10\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.1231 - accuracy: 0.9546 - val_loss: 0.4338 - val_accuracy: 0.8850\n",
      "Epoch 4/10\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.1193 - accuracy: 0.9571 - val_loss: 0.4083 - val_accuracy: 0.8933\n",
      "Epoch 5/10\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.1170 - accuracy: 0.9577 - val_loss: 0.4096 - val_accuracy: 0.8890\n",
      "Epoch 6/10\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.1129 - accuracy: 0.9596 - val_loss: 0.4100 - val_accuracy: 0.8949\n",
      "Epoch 7/10\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.1133 - accuracy: 0.9599 - val_loss: 0.3996 - val_accuracy: 0.8964\n",
      "Epoch 8/10\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.1104 - accuracy: 0.9600 - val_loss: 0.4211 - val_accuracy: 0.8867\n",
      "Epoch 9/10\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.1096 - accuracy: 0.9609 - val_loss: 0.4189 - val_accuracy: 0.8957\n",
      "Epoch 10/10\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.1043 - accuracy: 0.9623 - val_loss: 0.4679 - val_accuracy: 0.8893\n",
      "50000 50000\n",
      "Epoch 1/10\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.1061 - accuracy: 0.9620 - val_loss: 0.4504 - val_accuracy: 0.8896\n",
      "Epoch 2/10\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.1031 - accuracy: 0.9631 - val_loss: 0.4496 - val_accuracy: 0.8960\n",
      "Epoch 3/10\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.0996 - accuracy: 0.9639 - val_loss: 0.4504 - val_accuracy: 0.8957\n",
      "Epoch 4/10\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.0970 - accuracy: 0.9657 - val_loss: 0.4565 - val_accuracy: 0.8957\n",
      "Epoch 5/10\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.0949 - accuracy: 0.9663 - val_loss: 0.4430 - val_accuracy: 0.8974\n",
      "Epoch 6/10\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.0952 - accuracy: 0.9670 - val_loss: 0.4819 - val_accuracy: 0.8930\n",
      "Epoch 7/10\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.0929 - accuracy: 0.9665 - val_loss: 0.4950 - val_accuracy: 0.8958\n",
      "Epoch 8/10\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.0936 - accuracy: 0.9659 - val_loss: 0.4763 - val_accuracy: 0.8950\n",
      "Epoch 9/10\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.0897 - accuracy: 0.9691 - val_loss: 0.4793 - val_accuracy: 0.8943\n",
      "Epoch 10/10\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.0873 - accuracy: 0.9685 - val_loss: 0.5012 - val_accuracy: 0.8875\n",
      "50000 50000\n",
      "Epoch 1/10\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.0877 - accuracy: 0.9689 - val_loss: 0.4936 - val_accuracy: 0.8941\n",
      "Epoch 2/10\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.0845 - accuracy: 0.9694 - val_loss: 0.5186 - val_accuracy: 0.8938\n",
      "Epoch 3/10\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.0826 - accuracy: 0.9710 - val_loss: 0.5022 - val_accuracy: 0.8973\n",
      "Epoch 4/10\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.0802 - accuracy: 0.9712 - val_loss: 0.5346 - val_accuracy: 0.8916\n",
      "Epoch 5/10\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.0797 - accuracy: 0.9722 - val_loss: 0.5535 - val_accuracy: 0.8923\n",
      "Epoch 6/10\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.0786 - accuracy: 0.9723 - val_loss: 0.5399 - val_accuracy: 0.8941\n",
      "Epoch 7/10\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.0775 - accuracy: 0.9737 - val_loss: 0.5508 - val_accuracy: 0.8924\n",
      "Epoch 8/10\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.0768 - accuracy: 0.9725 - val_loss: 0.5478 - val_accuracy: 0.8864\n",
      "Epoch 9/10\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.0767 - accuracy: 0.9742 - val_loss: 0.5402 - val_accuracy: 0.8917\n",
      "Epoch 10/10\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.0759 - accuracy: 0.9739 - val_loss: 0.5552 - val_accuracy: 0.8894\n",
      "50000 50000\n",
      "Epoch 1/10\n",
      "391/391 [==============================] - 3s 6ms/step - loss: 0.0757 - accuracy: 0.9735 - val_loss: 0.5159 - val_accuracy: 0.8981\n",
      "Epoch 2/10\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.0759 - accuracy: 0.9743 - val_loss: 0.5572 - val_accuracy: 0.8932\n",
      "Epoch 3/10\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.0712 - accuracy: 0.9757 - val_loss: 0.5585 - val_accuracy: 0.8979\n",
      "Epoch 4/10\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.0677 - accuracy: 0.9762 - val_loss: 0.5509 - val_accuracy: 0.8960\n",
      "Epoch 5/10\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.0669 - accuracy: 0.9770 - val_loss: 0.5637 - val_accuracy: 0.8956\n",
      "Epoch 6/10\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.0691 - accuracy: 0.9760 - val_loss: 0.6716 - val_accuracy: 0.8829\n",
      "Epoch 7/10\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.0669 - accuracy: 0.9768 - val_loss: 0.5674 - val_accuracy: 0.8988\n",
      "Epoch 8/10\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.0657 - accuracy: 0.9771 - val_loss: 0.5875 - val_accuracy: 0.8947\n",
      "Epoch 9/10\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.0652 - accuracy: 0.9780 - val_loss: 0.5853 - val_accuracy: 0.8938\n",
      "Epoch 10/10\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.0636 - accuracy: 0.9780 - val_loss: 0.6121 - val_accuracy: 0.8930\n",
      "50000 50000\n",
      "Epoch 1/10\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.0666 - accuracy: 0.9767 - val_loss: 0.5993 - val_accuracy: 0.8934\n",
      "Epoch 2/10\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.0618 - accuracy: 0.9788 - val_loss: 0.5973 - val_accuracy: 0.8974\n",
      "Epoch 3/10\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.0650 - accuracy: 0.9777 - val_loss: 0.6375 - val_accuracy: 0.8927\n",
      "Epoch 4/10\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.0563 - accuracy: 0.9810 - val_loss: 0.7045 - val_accuracy: 0.8868\n",
      "Epoch 5/10\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.0626 - accuracy: 0.9788 - val_loss: 0.6413 - val_accuracy: 0.8929\n",
      "Epoch 6/10\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.0593 - accuracy: 0.9796 - val_loss: 0.6491 - val_accuracy: 0.8925\n",
      "Epoch 7/10\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.0600 - accuracy: 0.9799 - val_loss: 0.6636 - val_accuracy: 0.8927\n",
      "Epoch 8/10\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.0570 - accuracy: 0.9808 - val_loss: 0.6611 - val_accuracy: 0.8956\n",
      "Epoch 9/10\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.0554 - accuracy: 0.9808 - val_loss: 0.6555 - val_accuracy: 0.8984\n",
      "Epoch 10/10\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.0541 - accuracy: 0.9818 - val_loss: 0.6763 - val_accuracy: 0.8904\n",
      "50000 50000\n",
      "Epoch 1/10\n",
      "391/391 [==============================] - 3s 6ms/step - loss: 0.0588 - accuracy: 0.9802 - val_loss: 0.6306 - val_accuracy: 0.8998\n",
      "Epoch 2/10\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.0537 - accuracy: 0.9815 - val_loss: 0.7189 - val_accuracy: 0.8928\n",
      "Epoch 3/10\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.0528 - accuracy: 0.9827 - val_loss: 0.7120 - val_accuracy: 0.8928\n",
      "Epoch 4/10\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.0560 - accuracy: 0.9816 - val_loss: 0.6765 - val_accuracy: 0.8947\n",
      "Epoch 5/10\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.0550 - accuracy: 0.9815 - val_loss: 0.7504 - val_accuracy: 0.8934\n",
      "Epoch 6/10\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.0493 - accuracy: 0.9832 - val_loss: 0.6879 - val_accuracy: 0.8927\n",
      "Epoch 7/10\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.0545 - accuracy: 0.9824 - val_loss: 0.7197 - val_accuracy: 0.8910\n",
      "Epoch 8/10\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.0508 - accuracy: 0.9830 - val_loss: 0.7003 - val_accuracy: 0.8957\n",
      "Epoch 9/10\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.0515 - accuracy: 0.9832 - val_loss: 0.7682 - val_accuracy: 0.8888\n",
      "Epoch 10/10\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.0497 - accuracy: 0.9837 - val_loss: 0.6706 - val_accuracy: 0.8931\n"
     ]
    }
   ],
   "source": [
    "\n",
    "epoch_n = [10, 20, 30]\n",
    "batch_size_n = [32, 256, 512]\n",
    "#loss_function?\n",
    "#numero de neuronas\n",
    "#numero de capas?\n",
    "#descenso de gradientes\n",
    "#métricas? -> accuracy etc\n",
    "\n",
    "for x in range(1,10):\n",
    "\n",
    "    model.compile(optimizer=\"rmsprop\", \n",
    "                  loss=\"categorical_crossentropy\",\n",
    "                  metrics=[\"accuracy\"])\n",
    "\n",
    "    print(len(train_images), len(train_labels))\n",
    "    model.fit(train_images, train_labels, epochs=10, batch_size=128, \n",
    "              validation_data = (validation_images, validation_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72828e4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
