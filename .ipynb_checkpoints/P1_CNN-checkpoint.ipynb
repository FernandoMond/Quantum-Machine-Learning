{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e307c075",
   "metadata": {},
   "source": [
    "# Práctica Classical Neuronal Networks\n",
    "\n",
    "* Alejandro Mayorga\n",
    "* Fernando Mondragón\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1521cbba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\odnan\\anaconda3\\envs\\Quantum\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Primer paso: Cargar la database y distribuir las imágenes de entrenamiento y evaluación\n",
    "\n",
    "from tensorflow . keras . datasets import fashion_mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "#A mayores, cargamos la librería responsable de representar nuestras gráficas\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "( x_train , y_train ), ( x_test , y_test ) = fashion_mnist . load_data ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9cf58c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Primeramente, tenemos que preparar los datos de forma que sean fácilmente introducibles en nuestra red. Esto\n",
    "#implica reorganizar el array original en el que se nos es dada la información, así como para su tipo de datos a\n",
    "#float\n",
    "\n",
    "train_images = x_train.reshape((60000, 28 * 28))\n",
    "test_images = x_test.reshape((10000, 28 * 28))\n",
    "\n",
    "train_images = train_images.astype('float32') / 255\n",
    "test_images = test_images.astype('float32') / 255\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ed81913",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos un tercer grupo de validación\n",
    "\n",
    "\n",
    "validation_images = train_images[:10000] # Copy of x_train from the begining (0) to 9999\n",
    "validation_labels = y_train[:10000]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "final_training_images = train_images.copy()\n",
    "train_images = train_images[10000:] # Copy of x_train from 10000 to the end\n",
    "train_labels = y_train[10000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5339621c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Realizamos one-hot enconding para así disponer las etiquetas de forma que la red pueda entrenar\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "validation_labels = to_categorical(validation_labels)\n",
    "test_labels = to_categorical(y_test)\n",
    "final_training_labels = to_categorical(y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b22c1240",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opciones a probar\n",
    "\n",
    "epoch_n = [10,30]\n",
    "batch_size_n = [32,512]\n",
    "\n",
    "layers_n = [1,2]\n",
    "neurons_n = [16,64,128]\n",
    "learning_rates = [0.1,0.01,0.001]\n",
    "optimizers = [\"rmsprop\",\"Adam\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dd274fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.10220000147819519\n",
      "counter: 1\n",
      "Accuracy =  0.3237000107765198\n",
      "counter: 2\n",
      "Accuracy =  0.8302000164985657\n",
      "counter: 3\n",
      "Accuracy =  0.8564000129699707\n",
      "counter: 4\n",
      "Accuracy =  0.8652999997138977\n",
      "counter: 5\n",
      "Accuracy =  0.8658999800682068\n",
      "counter: 6\n",
      "Accuracy =  0.444599986076355\n",
      "counter: 7\n",
      "Accuracy =  0.33070001006126404\n",
      "counter: 8\n",
      "Accuracy =  0.8468000292778015\n",
      "counter: 9\n",
      "Accuracy =  0.8557999730110168\n",
      "counter: 10\n",
      "Accuracy =  0.883400022983551\n",
      "counter: 11\n",
      "Accuracy =  0.8858000040054321\n",
      "counter: 12\n",
      "Accuracy =  0.45239999890327454\n",
      "counter: 13\n",
      "Accuracy =  0.4059999883174896\n",
      "counter: 14\n",
      "Accuracy =  0.8561999797821045\n",
      "counter: 15\n",
      "Accuracy =  0.8626999855041504\n",
      "counter: 16\n",
      "Accuracy =  0.8845000267028809\n",
      "counter: 17\n",
      "Accuracy =  0.8920999765396118\n",
      "counter: 18\n",
      "Accuracy =  0.10270000249147415\n",
      "counter: 19\n",
      "Accuracy =  0.10270000249147415\n",
      "counter: 20\n",
      "Accuracy =  0.8312000036239624\n",
      "counter: 21\n",
      "Accuracy =  0.8471999764442444\n",
      "counter: 22\n",
      "Accuracy =  0.8704000115394592\n",
      "counter: 23\n",
      "Accuracy =  0.8668000102043152\n",
      "counter: 24\n",
      "Accuracy =  0.10379999876022339\n",
      "counter: 25\n",
      "Accuracy =  0.20200000703334808\n",
      "counter: 26\n",
      "Accuracy =  0.8267999887466431\n",
      "counter: 27\n",
      "Accuracy =  0.8596000075340271\n",
      "counter: 28\n",
      "Accuracy =  0.8819000124931335\n",
      "counter: 29\n",
      "Accuracy =  0.8855999708175659\n",
      "counter: 30\n",
      "Accuracy =  0.10270000249147415\n",
      "counter: 31\n",
      "Accuracy =  0.10220000147819519\n",
      "counter: 32\n",
      "Accuracy =  0.8393999934196472\n",
      "counter: 33\n",
      "Accuracy =  0.8603000044822693\n",
      "counter: 34\n",
      "Accuracy =  0.8848999738693237\n",
      "counter: 35\n",
      "Accuracy =  0.8881000280380249\n",
      "counter: 36\n",
      "Accuracy =  0.30320000648498535\n",
      "counter: 37\n",
      "Accuracy =  0.8033000230789185\n",
      "counter: 38\n",
      "Accuracy =  0.847000002861023\n",
      "counter: 39\n",
      "Accuracy =  0.8615999817848206\n",
      "counter: 40\n",
      "Accuracy =  0.8521000146865845\n",
      "counter: 41\n",
      "Accuracy =  0.8522999882698059\n",
      "counter: 42\n",
      "Accuracy =  0.5656999945640564\n",
      "counter: 43\n",
      "Accuracy =  0.7763000130653381\n",
      "counter: 44\n",
      "Accuracy =  0.8626000285148621\n",
      "counter: 45\n",
      "Accuracy =  0.8769000172615051\n",
      "counter: 46\n",
      "Accuracy =  0.8658999800682068\n",
      "counter: 47\n",
      "Accuracy =  0.8694999814033508\n",
      "counter: 48\n",
      "Accuracy =  0.6324999928474426\n",
      "counter: 49\n",
      "Accuracy =  0.7081999778747559\n",
      "counter: 50\n",
      "Accuracy =  0.8686000108718872\n",
      "counter: 51\n",
      "Accuracy =  0.8881000280380249\n",
      "counter: 52\n",
      "Accuracy =  0.8747000098228455\n",
      "counter: 53\n",
      "Accuracy =  0.8752999901771545\n",
      "counter: 54\n",
      "Accuracy =  0.25440001487731934\n",
      "counter: 55\n",
      "Accuracy =  0.6360999941825867\n",
      "counter: 56\n",
      "Accuracy =  0.8393999934196472\n",
      "counter: 57\n",
      "Accuracy =  0.8537999987602234\n",
      "counter: 58\n",
      "Accuracy =  0.8543000221252441\n",
      "counter: 59\n",
      "Accuracy =  0.8561999797821045\n",
      "counter: 60\n",
      "Accuracy =  0.20340000092983246\n",
      "counter: 61\n",
      "Accuracy =  0.8398000001907349\n",
      "counter: 62\n",
      "Accuracy =  0.8651999831199646\n",
      "counter: 63\n",
      "Accuracy =  0.882099986076355\n",
      "counter: 64\n",
      "Accuracy =  0.8690999746322632\n",
      "counter: 65\n",
      "Accuracy =  0.8765000104904175\n",
      "counter: 66\n",
      "Accuracy =  0.2732999920845032\n",
      "counter: 67\n",
      "Accuracy =  0.47859999537467957\n",
      "counter: 68\n",
      "Accuracy =  0.8650000095367432\n",
      "counter: 69\n",
      "Accuracy =  0.8809999823570251\n",
      "counter: 70\n",
      "Accuracy =  0.876800000667572\n",
      "counter: 71\n",
      "Accuracy =  0.8834999799728394\n",
      "counter: 72\n",
      "Accuracy =  0.210999995470047\n",
      "counter: 73\n",
      "Accuracy =  0.10270000249147415\n",
      "counter: 74\n",
      "Accuracy =  0.830299973487854\n",
      "counter: 75\n",
      "Accuracy =  0.838100016117096\n",
      "counter: 76\n",
      "Accuracy =  0.8704000115394592\n",
      "counter: 77\n",
      "Accuracy =  0.8712000250816345\n",
      "counter: 78\n",
      "Accuracy =  0.35420000553131104\n",
      "counter: 79\n",
      "Accuracy =  0.19220000505447388\n",
      "counter: 80\n",
      "Accuracy =  0.8565999865531921\n",
      "counter: 81\n",
      "Accuracy =  0.8658000230789185\n",
      "counter: 82\n",
      "Accuracy =  0.88919997215271\n",
      "counter: 83\n",
      "Accuracy =  0.8924000263214111\n",
      "counter: 84\n",
      "Accuracy =  0.486299991607666\n",
      "counter: 85\n",
      "Accuracy =  0.34130001068115234\n",
      "counter: 86\n",
      "Accuracy =  0.8593999743461609\n",
      "counter: 87\n",
      "Accuracy =  0.8647000193595886\n",
      "counter: 88\n",
      "Accuracy =  0.8888000249862671\n",
      "counter: 89\n",
      "Accuracy =  0.8946999907493591\n",
      "counter: 90\n",
      "Accuracy =  0.20350000262260437\n",
      "counter: 91\n",
      "Accuracy =  0.10270000249147415\n",
      "counter: 92\n",
      "Accuracy =  0.8352000117301941\n",
      "counter: 93\n",
      "Accuracy =  0.857200026512146\n",
      "counter: 94\n",
      "Accuracy =  0.870199978351593\n",
      "counter: 95\n",
      "Accuracy =  0.8773000240325928\n",
      "counter: 96\n",
      "Accuracy =  0.10270000249147415\n",
      "counter: 97\n",
      "Accuracy =  0.10270000249147415\n",
      "counter: 98\n",
      "Accuracy =  0.8174999952316284\n",
      "counter: 99\n",
      "Accuracy =  0.866100013256073\n",
      "counter: 100\n",
      "Accuracy =  0.8830999732017517\n",
      "counter: 101\n",
      "Accuracy =  0.8924999833106995\n",
      "counter: 102\n",
      "Accuracy =  0.10279999673366547\n",
      "counter: 103\n",
      "Accuracy =  0.10270000249147415\n",
      "counter: 104\n",
      "Accuracy =  0.8300999999046326\n",
      "counter: 105\n",
      "Accuracy =  0.8669999837875366\n",
      "counter: 106\n",
      "Accuracy =  0.886900007724762\n",
      "counter: 107\n",
      "Accuracy =  0.8960000276565552\n",
      "counter: 108\n",
      "Accuracy =  0.5419999957084656\n",
      "counter: 109\n",
      "Accuracy =  0.7574999928474426\n",
      "counter: 110\n",
      "Accuracy =  0.8518000245094299\n",
      "counter: 111\n",
      "Accuracy =  0.864300012588501\n",
      "counter: 112\n",
      "Accuracy =  0.8644000291824341\n",
      "counter: 113\n",
      "Accuracy =  0.8676000237464905\n",
      "counter: 114\n",
      "Accuracy =  0.5909000039100647\n",
      "counter: 115\n",
      "Accuracy =  0.7723000049591064\n",
      "counter: 116\n",
      "Accuracy =  0.878600001335144\n",
      "counter: 117\n",
      "Accuracy =  0.8798999786376953\n",
      "counter: 118\n",
      "Accuracy =  0.8823000192642212\n",
      "counter: 119\n",
      "Accuracy =  0.8859000205993652\n",
      "counter: 120\n",
      "Accuracy =  0.7200999855995178\n",
      "counter: 121\n",
      "Accuracy =  0.8217999935150146\n",
      "counter: 122\n",
      "Accuracy =  0.8816999793052673\n",
      "counter: 123\n",
      "Accuracy =  0.8910999894142151\n",
      "counter: 124\n",
      "Accuracy =  0.8924000263214111\n",
      "counter: 125\n",
      "Accuracy =  0.8907999992370605\n",
      "counter: 126\n",
      "Accuracy =  0.10270000249147415\n",
      "counter: 127\n",
      "Accuracy =  0.6647999882698059\n",
      "counter: 128\n",
      "Accuracy =  0.8306999802589417\n",
      "counter: 129\n",
      "Accuracy =  0.8637999892234802\n",
      "counter: 130\n",
      "Accuracy =  0.8679999709129333\n",
      "counter: 131\n",
      "Accuracy =  0.8669999837875366\n",
      "counter: 132\n",
      "Accuracy =  0.10270000249147415\n",
      "counter: 133\n",
      "Accuracy =  0.35109999775886536\n",
      "counter: 134\n",
      "Accuracy =  0.8738999962806702\n",
      "counter: 135\n",
      "Accuracy =  0.8841999769210815\n",
      "counter: 136\n",
      "Accuracy =  0.8888999819755554\n",
      "counter: 137\n",
      "Accuracy =  0.8899999856948853\n",
      "counter: 138\n",
      "Accuracy =  0.10260000079870224\n",
      "counter: 139\n",
      "Accuracy =  0.6424999833106995\n",
      "counter: 140\n",
      "Accuracy =  0.8830000162124634\n",
      "counter: 141\n",
      "Accuracy =  0.8884000182151794\n",
      "counter: 142\n",
      "Accuracy =  0.8980000019073486\n",
      "counter: 143\n",
      "Accuracy =  0.891700029373169\n",
      "counter: 144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHHCAYAAABDUnkqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAABF1ElEQVR4nO3deVxVdf7H8fcF2VVcEHCHzNz3hUzNSorSNNNMzQm30cYkTcrUTK2cRK3MTNMp0xoH06nRprJ0zCWt3JfUNHfFDdHMQDRQ+P7+6MH9eQOVCxcvHF7Px+M+5H7P95zz+R6Q++asNmOMEQAAgEV4uLsAAAAAVyLcAAAASyHcAAAASyHcAAAASyHcAAAASyHcAAAASyHcAAAASyHcAAAASyHcAAAASyHcACh0PvzwQ9lsNh09etQly1uzZo1sNpvWrFnjkuUVBfkZs6u3P3CrEW4AF3j33Xdls9kUERHh7lIAoNgj3AAuEB8fr7CwMG3atEkHDx50dzkAUKwRboB8OnLkiH744QdNnTpVFSpUUHx8vLtLuq7U1FR3lwAABY5wA+RTfHy8ypYtq44dO+qxxx67bri5cOGChg8frrCwMPn4+KhKlSqKjo7WuXPn7H1+//13vfzyy7rjjjvk6+urihUrqmvXrjp06JCk659HcfToUdlsNn344Yf2tr59+6pkyZI6dOiQOnTooFKlSql3796SpHXr1ql79+6qVq2afHx8VLVqVQ0fPlyXL1/OVvfPP/+sxx9/XBUqVJCfn59q1aqlMWPGSJJWr14tm82mJUuWZJtvwYIFstlsWr9+/Q23308//aT77rtPfn5+qlKliv7+978rMzMzx75ff/212rZtq4CAAJUqVUodO3bUTz/9dMPl38gnn3yiZs2ayc/PT0FBQfrLX/6ikydPOvRJTExUv379VKVKFfn4+KhixYp65JFHbno+Stb2T0hI0MMPP6ySJUuqcuXKmjlzpiRp165duu+++xQQEKDq1atrwYIF2ZZx+PBhde/eXeXKlZO/v7/uvPNOLV26NFu/EydOqEuXLgoICFBwcLCGDx+utLS0HOvauHGjHnzwQQUGBsrf31/t2rXT999/n6vt9e6776pevXry8fFRpUqVNGTIEF24cMGhz4EDB9StWzeFhobK19dXVapUUc+ePfXbb7/lah2AK5RwdwFAURcfH6+uXbvK29tbvXr10qxZs7R582a1aNHC3ufixYtq27at9u7dq/79+6tp06Y6d+6cPv/8c504cUJBQUHKyMjQww8/rJUrV6pnz54aNmyYUlJStGLFCu3evVs1atRwurarV68qKipKbdq00RtvvCF/f39Jf3yoX7p0SYMHD1b58uW1adMmvfPOOzpx4oQ++eQT+/w7d+5U27Zt5eXlpUGDBiksLEyHDh3SF198oddee0333HOPqlatqvj4eD366KPZtkuNGjXUqlWr69aXmJioe++9V1evXtWoUaMUEBCg9957T35+ftn6zp8/X3369FFUVJQmT56sS5cuadasWWrTpo22b9+usLAwp7bNhx9+qH79+qlFixaKi4vTmTNn9Pbbb+v777/X9u3bVaZMGUlSt27d9NNPP+mZZ55RWFiYkpKStGLFCiUkJNx0nRkZGXrooYd09913a8qUKYqPj1dMTIwCAgI0ZswY9e7dW127dtXs2bMVHR2tVq1aKTw8XJJ05swZ3XXXXbp06ZKGDh2q8uXL66OPPlLnzp316aef2rf35cuX1b59eyUkJGjo0KGqVKmS5s+fr1WrVmWrZ9WqVXrooYfUrFkzjR8/Xh4eHpo3b57uu+8+rVu3Ti1btrzuWF5++WW98sorioyM1ODBg7Vv3z77z/r3338vLy8vpaenKyoqSmlpaXrmmWcUGhqqkydP6ssvv9SFCxcUGBjo1PcIyDMDIM+2bNliJJkVK1YYY4zJzMw0VapUMcOGDXPoN27cOCPJLF68ONsyMjMzjTHGzJ0710gyU6dOvW6f1atXG0lm9erVDtOPHDliJJl58+bZ2/r06WMkmVGjRmVb3qVLl7K1xcXFGZvNZo4dO2Zvu/vuu02pUqUc2q6txxhjRo8ebXx8fMyFCxfsbUlJSaZEiRJm/Pjx2dZzrWeffdZIMhs3bnSYNzAw0EgyR44cMcYYk5KSYsqUKWMGDhzoMH9iYqIJDAzM1v5nf95u6enpJjg42NSvX99cvnzZ3u/LL780ksy4ceOMMcb8+uuvRpJ5/fXXb7j8nGRt/4kTJ9rbfv31V+Pn52dsNptZuHChvf3nn382khy2V9a2Wbdunb0tJSXFhIeHm7CwMJORkWGMMWbatGlGkvn3v/9t75eammpuv/12hzFnZmaamjVrmqioKIfv36VLl0x4eLi5//777W3z5s1z2P5JSUnG29vbPPDAA/b1GmPMjBkzjCQzd+5cY4wx27dvN5LMJ5984vT2AlyJw1JAPsTHxyskJET33nuvJMlms6lHjx5auHChMjIy7P3+85//qFGjRtn2bmTNk9UnKChIzzzzzHX75MXgwYOztV27ZyQ1NVXnzp3TXXfdJWOMtm/fLkk6e/as1q5dq/79+6tatWrXrSc6OlppaWn69NNP7W2LFi3S1atX9Ze//OWGtX311Ve68847HfYYVKhQwX74LMuKFSt04cIF9erVS+fOnbO/PD09FRERodWrV+diS/y/LVu2KCkpSU8//bR8fX3t7R07dlTt2rXth378/Pzk7e2tNWvW6Ndff3VqHVn++te/2r8uU6aMatWqpYCAAD3++OP29lq1aqlMmTI6fPiwve2rr75Sy5Yt1aZNG3tbyZIlNWjQIB09elR79uyx96tYsaIee+wxez9/f38NGjTIoY4dO3bowIEDeuKJJ/TLL7/Yt2Fqaqrat2+vtWvXXvdw4DfffKP09HQ9++yz8vD4/4+NgQMHqnTp0vbtlbVnZvny5bp06ZLT2wpwFcINkEcZGRlauHCh7r33Xh05ckQHDx7UwYMHFRERoTNnzmjlypX2vocOHVL9+vVvuLxDhw6pVq1aKlHCdUeLS5QooSpVqmRrT0hIUN++fVWuXDmVLFlSFSpUULt27STJfm5E1gftzequXbu2WrRo4XCuUXx8vO68807dfvvtN5z32LFjqlmzZrb2WrVqObw/cOCAJOm+++5ThQoVHF7/+9//lJSUdMP15LTenNaTNZ6s6T4+Ppo8ebK+/vprhYSE2A8vJSYm5mo9vr6+qlChgkNbYGCgqlSpki2wBgYGOgSoY8eO5VhfnTp1HMZw7Ngx3X777dmWd71t2KdPn2zbcM6cOUpLS7vueTHX217e3t667bbb7NPDw8MVGxurOXPmKCgoSFFRUZo5cybn2+CW45wbII9WrVql06dPa+HChVq4cGG26fHx8XrggQdcus7r7cG5di/RtXx8fBz+0s7qe//99+v8+fMaOXKkateurYCAAJ08eVJ9+/a97l/vNxIdHa1hw4bpxIkTSktL04YNGzRjxgynl3M9WTXNnz9foaGh2aa7MhD+2bPPPqtOnTrps88+0/LlyzV27FjFxcVp1apVatKkyQ3n9fT0dKrdGJPveq8naxu+/vrraty4cY59SpYsme/1vPnmm+rbt6/++9//6n//+5+GDh2quLg4bdiwIcegDRQEwg2QR/Hx8QoODrZf/XKtxYsXa8mSJZo9e7b8/PxUo0YN7d69+4bLq1GjhjZu3KgrV67Iy8srxz5ly5aVpGxXqGT95Zwbu3bt0v79+/XRRx8pOjra3r5ixQqHfrfddpsk3bRuSerZs6diY2P18ccf6/Lly/Ly8lKPHj1uOl/16tXtexSutW/fPof3WSdTBwcHKzIy8qbLzc16s9Zz3333ZVt31vRr1//cc8/pueee04EDB9S4cWO9+eab+te//pXvWm5U45+3g/TH1WtZ07P+3b17t4wxDuH3etuwdOnSTm/Da7dX1s+FJKWnp+vIkSPZltegQQM1aNBAL730kn744Qe1bt1as2fP1t///nen1gvkFYelgDy4fPmyFi9erIcffliPPfZYtldMTIxSUlL0+eefS/rjipsff/wxx0ums/5a79atm86dO5fjHo+sPtWrV5enp6fWrl3rMP3dd9/Nde1Zew2u3UtgjNHbb7/t0K9ChQq6++67NXfuXCUkJORYT5agoCA99NBD+te//qX4+Hg9+OCDCgoKumktHTp00IYNG7Rp0yZ729mzZ7NdTh8VFaXSpUtr4sSJunLlSrblnD179qbrulbz5s0VHBys2bNnO1wy/fXXX2vv3r3q2LGjJOnSpUv6/fffHeatUaOGSpUqdd1LrV2lQ4cO2rRpk8Ol9KmpqXrvvfcUFhamunXr2vudOnXK4ZynS5cu6b333nNYXrNmzVSjRg298cYbunjxYrb13WgbRkZGytvbW9OnT3f43n/wwQf67bff7NsrOTlZV69edZi3QYMG8vDwKPDtBVyLPTdAHnz++edKSUlR586dc5x+55132m/o16NHD40YMUKffvqpunfvrv79+6tZs2Y6f/68Pv/8c82ePVuNGjVSdHS0/vnPfyo2NlabNm1S27ZtlZqaqm+++UZPP/20HnnkEQUGBqp79+565513ZLPZVKNGDX355ZdOnXNSu3Zt1ahRQ88//7xOnjyp0qVL6z//+U+OJ8xOnz5dbdq0UdOmTTVo0CCFh4fr6NGjWrp0qXbs2OHQNzo62n5S64QJE3JVywsvvKD58+frwQcf1LBhw+yXglevXl07d+609ytdurRmzZqlJ598Uk2bNlXPnj1VoUIFJSQkaOnSpWrdurVTh8G8vLw0efJk9evXT+3atVOvXr3sl4KHhYVp+PDhkqT9+/erffv2evzxx1W3bl2VKFFCS5Ys0ZkzZ9SzZ89cry8vRo0apY8//lgPPfSQhg4dqnLlyumjjz7SkSNH9J///Md+uHHgwIGaMWOGoqOjtXXrVlWsWFHz58+3X/afxcPDQ3PmzNFDDz2kevXqqV+/fqpcubJOnjyp1atXq3Tp0vriiy9yrKVChQoaPXq0XnnlFT344IPq3Lmz9u3bp3fffVctWrSwnzi+atUqxcTEqHv37rrjjjt09epVzZ8/X56enurWrVuBbi/Agduu0wKKsE6dOhlfX1+Tmpp63T59+/Y1Xl5e5ty5c8YYY3755RcTExNjKleubLy9vU2VKlVMnz597NON+eOy3DFjxpjw8HDj5eVlQkNDzWOPPWYOHTpk73P27FnTrVs34+/vb8qWLWueeuops3v37hwvBQ8ICMixtj179pjIyEhTsmRJExQUZAYOHGh+/PHHbMswxpjdu3ebRx991JQpU8b4+vqaWrVqmbFjx2ZbZlpamilbtqwJDAx0uLz6Znbu3GnatWtnfH19TeXKlc2ECRPMBx984HApcpbVq1ebqKgoExgYaHx9fU2NGjVM3759zZYtW264jutdQr9o0SLTpEkT4+PjY8qVK2d69+5tTpw4YZ9+7tw5M2TIEFO7dm0TEBBgAgMDTUREhMNl19dzve3frl07U69evWzt1atXNx07dnRoO3TokHnsscfs275ly5bmyy+/zDbvsWPHTOfOnY2/v78JCgoyw4YNM8uWLctxzNu3bzddu3Y15cuXNz4+PqZ69erm8ccfNytXrrT3+fOl4FlmzJhhateubby8vExISIgZPHiw+fXXX+3TDx8+bPr3729q1KhhfH19Tbly5cy9995rvvnmm5tuL8CVbMYU4BlsAIqNq1evqlKlSurUqZM++OADd5cDoBjjnBsALvHZZ5/p7NmzDicpA4A7sOcGQL5s3LhRO3fu1IQJExQUFKRt27a5uyQAxRx7bgDky6xZszR48GAFBwfrn//8p7vLAQD23AAAAGthzw0AALAUwg0AALCUYncTv8zMTJ06dUqlSpXK15OWAQDArWOMUUpKiipVqpTtmXl/VuzCzalTp1S1alV3lwEAAPLg+PHjN30Ia7ELN6VKlZL0x8YpXbq0m6sBAAC5kZycrKpVq9o/x2+k2IWbrENRpUuXJtwAAFDE5OaUEk4oBgAAlkK4AQAAlkK4AQAAllLszrkBAADukZGRoStXrlx3ure3900v884Nwg0AAChQxhglJibqwoULN+zn4eGh8PBweXt752t9hBsAAFCgsoJNcHCw/P39c7ziKesmu6dPn1a1atXydaNdwg0AACgwGRkZ9mBTvnz5G/atUKGCTp06patXr8rLyyvP6+SEYgAAUGCyzrHx9/e/ad+sw1EZGRn5WifhBgAAFLjcHGZy1TMfCTcAAMBSCDcAAMBSCDcAAMBSCDcAAKDAGWNc0ic3CDcAAKDAZF3SfenSpZv2TU9PlyR5enrma53c5wYAABQYT09PlSlTRklJSZJ0w5v4nT17Vv7+/ipRIn/xhHADAADyJGzUUvvXRyd1vG6/0NBQSbIHnOvx8PDI992JJcINABQJWR8iN/oAKcpy+yGJoslms6lixYoKDg7mwZkoHPilA+RNcfi/Y/XQlRfXbpPitH1y8/Pu6emZ7/NpcoNwAwAu5MoPs+L0wVgcFJbv57Uh5Fq5rauwjONGCDeAisZ/1tywyjhQPFzvQ7Yw4f9U0US4sZD8pvHcLKswyc8vneJwuKA44fsJ3FhR+J3uSoQbFCn8FVX0uDJ4EGLcrzh8D5z9PcM2KXy4iR8AoFgKG7XU/qF97dco+thzA7hZUfuLyJVcdWgRzinOP3MoHgg3gEXldDlq1nsA1lec/wAg3ADANQiCQNFHuEGBYxd43uT2Q7aobd/CWG9x+Au3MG535B6h2zmEm0LG6r+ArD6+/CoOH7JWZPWfa1f+XN6Kn/HiEASs/jOXX4QbNysO/wlR/BS1D8PChA+t3LveeWVWYcUx3SqEG9hZ/ZdqQX3g5udKH6tuawBwJ8INCjX2bMHq+BkHXI9w4waFaZc9exDgLH5m/lDYtwOhCcUZdygGkCPu3gqgqGLPDZBPrnxgKYAbK+x7zFA4sOcGAABYCuGmCCoKhwiKQo3OsuKYAMCKCDcAAMBSCDcAAMBSOKEYlsZhpNxz1Y0Ji4qiVi+A3CPcAIBFENiAP3BYCgAAWAp7bm6R4vAXFfefQGHHz6h7sN1zrzh8VtwK7LkBAACWwp4bFDr85QIAyA/23AAAAEthzw0AAE5iD3PhRrgBAGTDhzeKMg5LAQAASyHcAAAAS3F7uJk5c6bCwsLk6+uriIgIbdq06Yb9p02bplq1asnPz09Vq1bV8OHD9fvvv9+iagEAQGHn1nCzaNEixcbGavz48dq2bZsaNWqkqKgoJSUl5dh/wYIFGjVqlMaPH6+9e/fqgw8+0KJFi/Tiiy/e4soBAEBh5dZwM3XqVA0cOFD9+vVT3bp1NXv2bPn7+2vu3Lk59v/hhx/UunVrPfHEEwoLC9MDDzygXr163XRvDwAAKD7cFm7S09O1detWRUZG/n8xHh6KjIzU+vXrc5znrrvu0tatW+1h5vDhw/rqq6/UoUOH664nLS1NycnJDi8gt8JGLeWqEQAoYtx2Kfi5c+eUkZGhkJAQh/aQkBD9/PPPOc7zxBNP6Ny5c2rTpo2MMbp69ar+9re/3fCwVFxcnF555RWX1g4AAAovt59Q7Iw1a9Zo4sSJevfdd7Vt2zYtXrxYS5cu1YQJE647z+jRo/Xbb7/ZX8ePH7+FFQMAgFvNbXtugoKC5OnpqTNnzji0nzlzRqGhoTnOM3bsWD355JP661//Kklq0KCBUlNTNWjQII0ZM0YeHtmzmo+Pj3x8fFw/AAAAUCi5bc+Nt7e3mjVrppUrV9rbMjMztXLlSrVq1SrHeS5dupQtwHh6ekqSjDEFVywAACgy3Pr4hdjYWPXp00fNmzdXy5YtNW3aNKWmpqpfv36SpOjoaFWuXFlxcXGSpE6dOmnq1Klq0qSJIiIidPDgQY0dO1adOnWyhxwAAFC8uTXc9OjRQ2fPntW4ceOUmJioxo0ba9myZfaTjBMSEhz21Lz00kuy2Wx66aWXdPLkSVWoUEGdOnXSa6+95q4hAACAQsbtD86MiYlRTExMjtPWrFnj8L5EiRIaP368xo8ffwsqAwAARVGRuloKAADgZgg3AADAUgg3wC3C3Y4B4NYg3AAAAEtx+wnFAADcCtfuOT06qaMbK0FBY88NAACwFMINAACwFMINAACwFMINAACwFMINAACwFMINAKBQ4x5RcBbhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWEoJdxcAAEBRwJPJiw723AAAAEsh3AAAAEsh3AAAAEsh3AAAAEvhhGKgiLn2pMajkzq6sRIAKJzYcwMAACyFcAMAACyFcAMAACyFcAMAACyFcAMAACyFcAMAACyFcAMAACyFcAMAACyFcAMAACyFcAMAACyFcAMAACyFcAMAACyFcAMAACyFcAMAACyFcAMAACyFcAMAACylhLsLAACgOAsbtdTdJVgOe24AAIClEG4AAIClEG4AAIClEG4AAIClEG4AAIClEG4AAICl5OlS8IyMDH322Wfau3evJKlevXrq3LmzPD09XVocAACAs5wONwcPHlTHjh114sQJ1apVS5IUFxenqlWraunSpapRo4bLiwQAAMgtpw9LDR06VLfddpuOHz+ubdu2adu2bUpISFB4eLiGDh1aEDUCAIBbLGzU0iJ7g0Gn99x8++232rBhg8qVK2dvK1++vCZNmqTWrVu7tDgAAABnOR1ufHx8lJKSkq394sWL8vb2dklRAG6NovpXGQDciNOHpR5++GENGjRIGzdulDFGxhht2LBBf/vb39S5c+eCqBEAACDXnN5zM336dPXp00etWrWSl5eXJOnq1avq3Lmz3n77bZcXCIA9LADgDKfDTZkyZfTf//5XBw4c0M8//yxJqlOnjm6//XaXFwcAAOCsPN3nRpJq1qypmjVrurIWAACAfMtVuImNjc31AqdOnZrnYgAAAPIrV+Fm+/btuVqYzWbLVzEAAAD5latws3r16oKuAwAAwCXy/ODMgwcPavny5bp8+bIkyRjjsqIAAADyyulw88svv6h9+/a644471KFDB50+fVqSNGDAAD333HMuLxAAAMAZToeb4cOHy8vLSwkJCfL397e39+jRQ8uWLXO6gJkzZyosLEy+vr6KiIjQpk2bbtj/woULGjJkiCpWrCgfHx/dcccd+uqrr5xeLwAAsCanLwX/3//+p+XLl6tKlSoO7TVr1tSxY8ecWtaiRYsUGxur2bNnKyIiQtOmTVNUVJT27dun4ODgbP3T09N1//33Kzg4WJ9++qkqV66sY8eOqUyZMs4OAwAAWJTT4SY1NdVhj02W8+fPy8fHx6llTZ06VQMHDlS/fv0kSbNnz9bSpUs1d+5cjRo1Klv/uXPn6vz58/rhhx/sd0cOCwtzdggAAMDCnD4s1bZtW/3zn/+0v7fZbMrMzNSUKVN077335no56enp2rp1qyIjI/+/GA8PRUZGav369TnO8/nnn6tVq1YaMmSIQkJCVL9+fU2cOFEZGRnODgMAAFiU03tupkyZovbt22vLli1KT0/XCy+8oJ9++knnz5/X999/n+vlnDt3ThkZGQoJCXFoDwkJsT/W4c8OHz6sVatWqXfv3vrqq6908OBBPf3007py5YrGjx+f4zxpaWlKS0uzv09OTs51jQAAoOhxes9N/fr1tX//frVp00aPPPKIUlNT1bVrV23fvl01atQoiBrtMjMzFRwcrPfee0/NmjVTjx49NGbMGM2ePfu688TFxSkwMND+qlq1aoHWCAAA3CtPz5YKDAzUmDFj8rXioKAgeXp66syZMw7tZ86cUWhoaI7zVKxYUV5eXvL09LS31alTR4mJiUpPT5e3t3e2eUaPHu3w+Ijk5GQCDgAAFparcLNz585cL7Bhw4a56uft7a1mzZpp5cqV6tKli6Q/9sysXLlSMTExOc7TunVrLViwQJmZmfLw+GOn0/79+1WxYsUcg40k+fj4OH2iMwAAKLpyFW4aN24sm80mY4zD86Oy7kp8bZszJ/fGxsaqT58+at68uVq2bKlp06YpNTXVfvVUdHS0KleurLi4OEnS4MGDNWPGDA0bNkzPPPOMDhw4oIkTJ2ro0KG5XicAoPgIG7XU3SXADXIVbo4cOWL/evv27Xr++ec1YsQItWrVSpK0fv16vfnmm5oyZYpTK+/Ro4fOnj2rcePGKTExUY0bN9ayZcvsJxknJCTY99BIUtWqVbV8+XINHz5cDRs2VOXKlTVs2DCNHDnSqfUCAADrylW4qV69uv3r7t27a/r06erQoYO9rWHDhqpatarGjh1rP8SUWzExMdc9DLVmzZpsba1atdKGDRucWgcAACg+nL5aateuXQoPD8/WHh4erj179rikKAAAgLxyOtzUqVNHcXFxSk9Pt7elp6crLi5OderUcWlxAAAAznL6UvDZs2erU6dOqlKliv3KqJ07d8pms+mLL75weYEAAADOcDrctGzZUocPH1Z8fLz9TsI9evTQE088oYCAAJcXCAAA4Iw83cQvICBAgwYNcnUtAAAA+ZancHPo0CFNmzZNe/fulSTVq1dPQ4cOLfDHLwAAANyM0ycUL1++XHXr1tWmTZvUsGFDNWzYUBs2bFC9evW0YsWKgqgRAAAg15zeczNq1CgNHz5ckyZNytY+cuRI3X///S4rDijqsu6OenRSRzdXAgDFh9N7bvbu3asBAwZka+/fvz/3uQEAAG7ndLipUKGCduzYka19x44dCg4OdkVNAAAAeeb0YamBAwdq0KBBOnz4sO666y5J0vfff6/JkycrNjbW5QUCAAA4w+lwM3bsWJUqVUpvvvmmRo8eLUmqVKmSXn75ZZ7ODQAA3M7pcGOz2TR8+HANHz5cKSkpkqRSpUq5vDAAAIC8yNN9brIQagAAQGHjdLj55ZdfNG7cOK1evVpJSUnKzMx0mH7+/HmXFQcAAOAsp8PNk08+qYMHD2rAgAEKCQmRzWYriLoAAADyxOlws27dOn333Xdq1KhRQdQDACjmsm5+KXEDTOSN0/e5qV27ti5fvlwQtQAAAOSb0+Hm3Xff1ZgxY/Ttt9/ql19+UXJyssMLAADAnZw+LFWmTBklJyfrvvvuc2g3xshmsykjI8NlxQEAADjL6XDTu3dveXl5acGCBZxQDAAACh2nw83u3bu1fft21apVqyDqAQAAyBenz7lp3ry5jh8/XhC1AAAA5JvTe26eeeYZDRs2TCNGjFCDBg3k5eXlML1hw4YuKw4AAMBZToebHj16SJL69+9vb7PZbJxQDAAACgWnw82RI0cKog4AAACXcDrcVK9evSDqAAAAcAmnTygGAAAozAg3AADAUgg3AADAUgg3AADAUvIUbi5cuKA5c+Zo9OjROn/+vCRp27ZtOnnypEuLAwAAcJbTV0vt3LlTkZGRCgwM1NGjRzVw4ECVK1dOixcvVkJCgv75z38WRJ0AAAC54vSem9jYWPXt21cHDhyQr6+vvb1Dhw5au3atS4sDAABwltPhZvPmzXrqqaeytVeuXFmJiYkuKQoAACCvnA43Pj4+Sk5Ozta+f/9+VahQwSVFAQAA5JXT4aZz58569dVXdeXKFUl/PFcqISFBI0eOVLdu3VxeIAAAgDOcDjdvvvmmLl68qODgYF2+fFnt2rXT7bffrlKlSum1114riBoBAAByzemrpQIDA7VixQp999132rlzpy5evKimTZsqMjKyIOoDAEsIG7XU/vXRSR3dWAlgfU6Hmyxt2rRRmzZtXFkLAABAvuUq3EyfPj3XCxw6dGieiwEAAMivXIWbt956y+H92bNndenSJZUpU0bSH3cs9vf3V3BwMOEGQL5lHcLh8A2AvMjVCcVHjhyxv1577TU1btxYe/fu1fnz53X+/Hnt3btXTZs21YQJEwq6XgAAgBty+mqpsWPH6p133lGtWrXsbbVq1dJbb72ll156yaXFAQAAOMvpcHP69GldvXo1W3tGRobOnDnjkqIAAADyyulw0759ez311FPatm2bvW3r1q0aPHgwl4MDAAC3czrczJ07V6GhoWrevLl8fHzk4+Ojli1bKiQkRHPmzCmIGgEAAHLN6fvcVKhQQV999ZUOHDigvXv3SpJq166tO+64w+XFAQAAOCvPN/GrWbOmatas6cpaAAAA8s3pw1IAAACFGeEGAABYSp4PS6Ho4IF9AIDihD03AADAUpwON2FhYXr11VeVkJBQEPUAAADki9Ph5tlnn9XixYt122236f7779fChQuVlpZWELUVe2GjljocUgIAADeXp3CzY8cObdq0SXXq1NEzzzyjihUrKiYmxuGuxQAAAO6Q53NumjZtqunTp+vUqVMaP3685syZoxYtWqhx48aaO3eujDGurBMAACBX8ny11JUrV7RkyRLNmzdPK1as0J133qkBAwboxIkTevHFF/XNN99owYIFrqwVAADgppwON9u2bdO8efP08ccfy8PDQ9HR0XrrrbdUu3Zte59HH31ULVq0cGmhAAAAueF0uGnRooXuv/9+zZo1S126dJGXl1e2PuHh4erZs6dLCgQAAHCG0+Hm8OHDql69+g37BAQEaN68eXkuCgAAIK+cPqE4KSlJGzduzNa+ceNGbdmyxSVFAQAA5JXT4WbIkCE6fvx4tvaTJ09qyJAhLikKAAAgr5wON3v27FHTpk2ztTdp0kR79uxxSVEAAAB55XS48fHx0ZkzZ7K1nz59WiVK8BxOAADgXk6HmwceeECjR4/Wb7/9Zm+7cOGCXnzxRd1///0uLQ4AAMBZTu9qeeONN3T33XerevXqatKkiSRpx44dCgkJ0fz5811eIAAAgDOcDjeVK1fWzp07FR8frx9//FF+fn7q16+fevXqleM9bwAAAG6lPD1bKiAgQIMGDdLMmTP1xhtvKDo6Ol/BZubMmQoLC5Ovr68iIiK0adOmXM23cOFC2Ww2denSJc/rBgAA1pLnM4D37NmjhIQEpaenO7R37tzZqeUsWrRIsbGxmj17tiIiIjRt2jRFRUVp3759Cg4Ovu58R48e1fPPP6+2bdvmqX4AAGBNebpD8aOPPqpdu3bJZrPZn/5ts9kkSRkZGU4tb+rUqRo4cKD69esnSZo9e7aWLl2quXPnatSoUTnOk5GRod69e+uVV17RunXrdOHCBWeHUayFjVoqSTo6qaObKwEAwPWcPiw1bNgwhYeHKykpSf7+/vrpp5+0du1aNW/eXGvWrHFqWenp6dq6dasiIyP/vyAPD0VGRmr9+vXXne/VV19VcHCwBgwYcNN1pKWlKTk52eEFAACsy+lws379er366qsKCgqSh4eHPDw81KZNG8XFxWno0KFOLevcuXPKyMhQSEiIQ3tISIgSExNznOe7777TBx98oPfffz9X64iLi1NgYKD9VbVqVadqBAAARYvT4SYjI0OlSpWSJAUFBenUqVOSpOrVq2vfvn2ure5PUlJS9OSTT+r9999XUFBQrubJuidP1iunR0cAAADrcPqcm/r16+vHH39UeHi4IiIiNGXKFHl7e+u9997Tbbfd5tSygoKC5Onpme2Ox2fOnFFoaGi2/ocOHdLRo0fVqVMne1tmZuYfAylRQvv27VONGjUc5vHx8ZGPj49TdQEAgKLL6T03L730kj1QvPrqqzpy5Ijatm2rr776StOnT3dqWd7e3mrWrJlWrlxpb8vMzNTKlSvVqlWrbP1r166tXbt2aceOHfZX586dde+992rHjh0ccgIAAM7vuYmKirJ/ffvtt+vnn3/W+fPnVbZsWfsVU86IjY1Vnz591Lx5c7Vs2VLTpk1Tamqq/eqp6OhoVa5cWXFxcfL19VX9+vUd5i9TpowkZWsHAADFk1Ph5sqVK/Lz89OOHTscwkS5cuXyXECPHj109uxZjRs3TomJiWrcuLGWLVtmP8k4ISFBHh55utcgAAAohpwKN15eXqpWrZrT97K5mZiYGMXExOQ47WaXl3/44YcurQUAABRtTu8SGTNmjF588UWdP3++IOoBAADIF6fPuZkxY4YOHjyoSpUqqXr16goICHCYvm3bNpcVBwAA4Cynww0PqQQAAIWZ0+Fm/PjxBVEHAACAS3AZEgAAsBSn99x4eHjc8H42rr6SCgAAwBlOh5slS5Y4vL9y5Yq2b9+ujz76SK+88orLCgMAAMgLp8PNI488kq3tscceU7169bRo0SINGDDAJYUBAADkhcvOubnzzjsdnhEFAADgDi4JN5cvX9b06dNVuXJlVywOAAAgz5w+LPXnB2QaY5SSkiJ/f3/961//cmlxAAAAznI63Lz11lsO4cbDw0MVKlRQRESEypYt69LiAMCdwkYttX99dFJHN1YCwBlOh5u+ffsWQBkAACC/sgJ5cQ/jTp9zM2/ePH3yySfZ2j/55BN99NFHLikKAAAgr5wON3FxcQoKCsrWHhwcrIkTJ7qkKAAAgLxyOtwkJCQoPDw8W3v16tWVkJDgkqIAAADyyulzboKDg7Vz506FhYU5tP/4448qX768q+oCAMu69kRlAK7n9J6bXr16aejQoVq9erUyMjKUkZGhVatWadiwYerZs2dB1AgAAJBrTu+5mTBhgo4ePar27durRIk/Zs/MzFR0dDTn3AAAALdzOtx4e3tr0aJF+vvf/64dO3bIz89PDRo0UPXq1QuiPgAAAKc4HW6y1KxZUzVr1nRlLbgB7l0AAEDuOH3OTbdu3TR58uRs7VOmTFH37t1dUhQAAEBeOR1u1q5dqw4dOmRrf+ihh7R27VqXFAUAAJBXToebixcvytvbO1u7l5eXkpOTXVKUVYSNWsolnwAA3GJOh5sGDRpo0aJF2doXLlyounXruqQoAACAvHL6hOKxY8eqa9euOnTokO677z5J0sqVK/Xxxx/n+MwpAACAW8npcNOpUyd99tlnmjhxoj799FP5+fmpYcOG+uabb9SuXbuCqBEAACDX8nQpeMeOHdWxY/ZLknfv3q369evnuygAAIC8cvqcmz9LSUnRe++9p5YtW6pRo0auqAkAACDP8hxu1q5dq+joaFWsWFFvvPGG7rvvPm3YsMGVtQEAADjNqcNSiYmJ+vDDD/XBBx8oOTlZjz/+uNLS0vTZZ59xpRQAACgUcr3nplOnTqpVq5Z27typadOm6dSpU3rnnXcKsjbALbg/EQAUbbnec/P1119r6NChGjx4MM+UAgAAhVau99x89913SklJUbNmzRQREaEZM2bo3LlzBVkbAACA03Idbu688069//77On36tJ566iktXLhQlSpVUmZmplasWKGUlJSCrBMAACBXnL5aKiAgQP3799d3332nXbt26bnnntOkSZMUHByszp07F0SNAAAAuZav+9zUqlVLU6ZM0YkTJ/Txxx+7qiYAAIA8y/dN/CTJ09NTXbp00eeff+6KxQEAAOSZS8INAABAYUG4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AVAo8EwvAK5CuAEAAJZCuAEAAJZCuAEAAJZCuAEAAJZCuAEAAJZCuAEAAJZSwt0FALi1uNwagNWx5wYAAFgK4QYAAFgK4QYAAFgK4QYAAFgK4QYAAFgK4QYAAFgK4QYAAFgK4QYAAFgK4QYAAFgK4QYAAFgK4QYAAFgK4QYAAFgK4QYAAFgK4QYAAFgK4QYAAFgK4QYAAFhKoQg3M2fOVFhYmHx9fRUREaFNmzZdt+/777+vtm3bqmzZsipbtqwiIyNv2B9A8RM2aqnCRi11dxkA3MTt4WbRokWKjY3V+PHjtW3bNjVq1EhRUVFKSkrKsf+aNWvUq1cvrV69WuvXr1fVqlX1wAMP6OTJk7e4cgAAUBi5PdxMnTpVAwcOVL9+/VS3bl3Nnj1b/v7+mjt3bo794+Pj9fTTT6tx48aqXbu25syZo8zMTK1cufIWVw4AAAqjEu5ceXp6urZu3arRo0fb2zw8PBQZGan169fnahmXLl3SlStXVK5cuRynp6WlKS0tzf4+OTk5f0UDsMs69HN0Ukc3V1K8XHvIjW0PZOfWcHPu3DllZGQoJCTEoT0kJEQ///xzrpYxcuRIVapUSZGRkTlOj4uL0yuvvJLvWlGwOD8CAOAqbj8slR+TJk3SwoULtWTJEvn6+ubYZ/To0frtt9/sr+PHj9/iKgEAwK3k1j03QUFB8vT01JkzZxzaz5w5o9DQ0BvO+8Ybb2jSpEn65ptv1LBhw+v28/HxkY+Pj0vqBQAAhZ9b99x4e3urWbNmDicDZ50c3KpVq+vON2XKFE2YMEHLli1T8+bNb0WpAMAl5kAR4dY9N5IUGxurPn36qHnz5mrZsqWmTZum1NRU9evXT5IUHR2typUrKy4uTpI0efJkjRs3TgsWLFBYWJgSExMlSSVLllTJkiXdNg4AAFA4uD3c9OjRQ2fPntW4ceOUmJioxo0ba9myZfaTjBMSEuTh8f87mGbNmqX09HQ99thjDssZP368Xn755VtZOgAAKITcHm4kKSYmRjExMTlOW7NmjcP7o0ePFnxBAACgyCrSV0sBAAD8GeEGAABYCuEGAABYCuEGAABYCuEGAABYCuEGAABYCuEGAABYCuEGAABYCuEGAABYCuEGAABYCuEGAABYCuEGAABYCuEGAABYCuEGAABYCuEGAABYCuEGAABYCuEGAABYCuEGAABYCuEGAABYCuEGAABYCuEGAABYCuEGAABYCuEGAABYCuEGAABYCuEGAABYCuEGAABYCuEGAABYCuEGAABYCuEGAABYCuEGAABYCuEGAABYSgl3F4CiJWzU0hzbj07q6LJl5UXWsvJSB6zN6j8b+f1/dO32ye+2cuWyrM6V24dtnR3hxsX4IXM/V4YmAChOrPIZxmEpAABgKYQbAABgKYQbAABgKYQbAABgKYQbAABgKYQbAABgKYQbAABgKYQbAABgKYQbAABgKYQbAABgKYQbAABgKYQbAABgKYQbAABgKYQbAABgKYQbAABgKYQbAABgKYQbAABgKYQbAABgKYQbAABgKYQbAABgKYQbAABgKYQbAABgKYQbAABgKYQbAABgKYQbAABgKYQbAABgKYQbAABgKYQbAABgKYQbAABgKYQbAABgKYQbAABgKYQbAABgKYQbAABgKYQbAABgKYUi3MycOVNhYWHy9fVVRESENm3adMP+n3zyiWrXri1fX181aNBAX3311S2qFAAAFHZuDzeLFi1SbGysxo8fr23btqlRo0aKiopSUlJSjv1/+OEH9erVSwMGDND27dvVpUsXdenSRbt3777FlQMAgMLI7eFm6tSpGjhwoPr166e6detq9uzZ8vf319y5c3Ps//bbb+vBBx/UiBEjVKdOHU2YMEFNmzbVjBkzbnHlAACgMHJruElPT9fWrVsVGRlpb/Pw8FBkZKTWr1+f4zzr16936C9JUVFR1+0PAACKlxLuXPm5c+eUkZGhkJAQh/aQkBD9/PPPOc6TmJiYY//ExMQc+6elpSktLc3+/rfffpMkJScn56f068pMu2Rffk5f38j15snN17lVWJZbHGpnm9y65eZnHQW13OJQO9vk1i03P+soqOXeaB0F8RmbtUxjzM07Gzc6efKkkWR++OEHh/YRI0aYli1b5jiPl5eXWbBggUPbzJkzTXBwcI79x48fbyTx4sWLFy9evCzwOn78+E3zhVv33AQFBcnT01NnzpxxaD9z5oxCQ0NznCc0NNSp/qNHj1ZsbKz9fWZmps6fP6/y5cvLZrPlcwTZJScnq2rVqjp+/LhKly7t8uUXZoy9+I29uI5bYuzFcezFddxS4Ri7MUYpKSmqVKnSTfu6Ndx4e3urWbNmWrlypbp06SLpj/CxcuVKxcTE5DhPq1attHLlSj377LP2thUrVqhVq1Y59vfx8ZGPj49DW5kyZVxR/g2VLl262P3wZ2HsxW/sxXXcEmMvjmMvruOW3D/2wMDAXPVza7iRpNjYWPXp00fNmzdXy5YtNW3aNKWmpqpfv36SpOjoaFWuXFlxcXGSpGHDhqldu3Z688031bFjRy1cuFBbtmzRe++9585hAACAQsLt4aZHjx46e/asxo0bp8TERDVu3FjLli2znzSckJAgD4//v6jrrrvu0oIFC/TSSy/pxRdfVM2aNfXZZ5+pfv367hoCAAAoRNwebiQpJibmuoeh1qxZk62te/fu6t69ewFXlTc+Pj4aP358tkNhxQFjL35jL67jlhh7cRx7cR23VPTGbjMmN9dUAQAAFA1uv0MxAACAKxFuAACApRBuAACApRBuAACApRBuXGzmzJkKCwuTr6+vIiIitGnTJneX5FJxcXFq0aKFSpUqpeDgYHXp0kX79u1z6PP7779ryJAhKl++vEqWLKlu3bplu6t0UTdp0iTZbDaHm0laedwnT57UX/7yF5UvX15+fn5q0KCBtmzZYp9ujNG4ceNUsWJF+fn5KTIyUgcOHHBjxa6RkZGhsWPHKjw8XH5+fqpRo4YmTJjg8Gwbq4x97dq16tSpkypVqiSbzabPPvvMYXpuxnn+/Hn17t1bpUuXVpkyZTRgwABdvHjxFo4ib2409itXrmjkyJFq0KCBAgICVKlSJUVHR+vUqVMOyyiKY7/Z9/xaf/vb32Sz2TRt2jSH9sI6bsKNCy1atEixsbEaP368tm3bpkaNGikqKkpJSUnuLs1lvv32Ww0ZMkQbNmzQihUrdOXKFT3wwANKTU219xk+fLi++OILffLJJ/r222916tQpde3a1Y1Vu9bmzZv1j3/8Qw0bNnRot+q4f/31V7Vu3VpeXl76+uuvtWfPHr355psqW7asvc+UKVM0ffp0zZ49Wxs3blRAQICioqL0+++/u7Hy/Js8ebJmzZqlGTNmaO/evZo8ebKmTJmid955x97HKmNPTU1Vo0aNNHPmzByn52acvXv31k8//aQVK1boyy+/1Nq1azVo0KBbNYQ8u9HYL126pG3btmns2LHatm2bFi9erH379qlz584O/Yri2G/2Pc+yZMkSbdiwIcfHHhTacd/06VPItZYtW5ohQ4bY32dkZJhKlSqZuLg4N1ZVsJKSkowk8+233xpjjLlw4YLx8vIyn3zyib3P3r17jSSzfv16d5XpMikpKaZmzZpmxYoVpl27dmbYsGHGGGuPe+TIkaZNmzbXnZ6ZmWlCQ0PN66+/bm+7cOGC8fHxMR9//PGtKLHAdOzY0fTv39+hrWvXrqZ3797GGOuOXZJZsmSJ/X1uxrlnzx4jyWzevNne5+uvvzY2m82cPHnyltWeX38ee042bdpkJJljx44ZY6wx9uuN+8SJE6Zy5cpm9+7dpnr16uatt96yTyvM42bPjYukp6dr69atioyMtLd5eHgoMjJS69evd2NlBeu3336TJJUrV06StHXrVl25csVhO9SuXVvVqlWzxHYYMmSIOnbs6DA+ydrj/vzzz9W8eXN1795dwcHBatKkid5//3379CNHjigxMdFh7IGBgYqIiCjyY7/rrru0cuVK7d+/X5L0448/6rvvvtNDDz0kydpjv1Zuxrl+/XqVKVNGzZs3t/eJjIyUh4eHNm7ceMtrLki//fabbDab/TmFVh17ZmamnnzySY0YMUL16tXLNr0wj7tQ3KHYCs6dO6eMjAz7YyOyhISE6Oeff3ZTVQUrMzNTzz77rFq3bm1//EViYqK8vb2zPZw0JCREiYmJbqjSdRYuXKht27Zp8+bN2aZZedyHDx/WrFmzFBsbqxdffFGbN2/W0KFD5e3trT59+tjHl9PPflEf+6hRo5ScnKzatWvL09NTGRkZeu2119S7d29JsvTYr5WbcSYmJio4ONhheokSJVSuXDlLbYvff/9dI0eOVK9evewPkLTq2CdPnqwSJUpo6NChOU4vzOMm3CDPhgwZot27d+u7775zdykF7vjx4xo2bJhWrFghX19fd5dzS2VmZqp58+aaOHGiJKlJkybavXu3Zs+erT59+ri5uoL173//W/Hx8VqwYIHq1aunHTt26Nlnn1WlSpUsP3Zkd+XKFT3++OMyxmjWrFnuLqdAbd26VW+//ba2bdsmm83m7nKcxmEpFwkKCpKnp2e2q2POnDmj0NBQN1VVcGJiYvTll19q9erVqlKlir09NDRU6enpunDhgkP/or4dtm7dqqSkJDVt2lQlSpRQiRIl9O2332r69OkqUaKEQkJCLDluSapYsaLq1q3r0FanTh0lJCRIkn18VvzZHzFihEaNGqWePXuqQYMGevLJJzV8+HDFxcVJsvbYr5WbcYaGhma7eOLq1as6f/68JbZFVrA5duyYVqxYYd9rI1lz7OvWrVNSUpKqVatm/5137NgxPffccwoLC5NUuMdNuHERb29vNWvWTCtXrrS3ZWZmauXKlWrVqpUbK3MtY4xiYmK0ZMkSrVq1SuHh4Q7TmzVrJi8vL4ftsG/fPiUkJBTp7dC+fXvt2rVLO3bssL+aN2+u3r1727+24rglqXXr1tku99+/f7+qV68uSQoPD1doaKjD2JOTk7Vx48YiP/ZLly7Jw8Px16Snp6cyMzMlWXvs18rNOFu1aqULFy5o69at9j6rVq1SZmamIiIibnnNrpQVbA4cOKBvvvlG5cuXd5huxbE/+eST2rlzp8PvvEqVKmnEiBFavny5pEI+breezmwxCxcuND4+PubDDz80e/bsMYMGDTJlypQxiYmJ7i7NZQYPHmwCAwPNmjVrzOnTp+2vS5cu2fv87W9/M9WqVTOrVq0yW7ZsMa1atTKtWrVyY9UF49qrpYyx7rg3bdpkSpQoYV577TVz4MABEx8fb/z9/c2//vUve59JkyaZMmXKmP/+979m586d5pFHHjHh4eHm8uXLbqw8//r06WMqV65svvzyS3PkyBGzePFiExQUZF544QV7H6uMPSUlxWzfvt1s377dSDJTp04127dvt18RlJtxPvjgg6ZJkyZm48aN5rvvvjM1a9Y0vXr1cteQcu1GY09PTzedO3c2VapUMTt27HD4vZeWlmZfRlEc+82+53/256uljCm84ybcuNg777xjqlWrZry9vU3Lli3Nhg0b3F2SS0nK8TVv3jx7n8uXL5unn37alC1b1vj7+5tHH33UnD592n1FF5A/hxsrj/uLL74w9evXNz4+PqZ27drmvffec5iemZlpxo4da0JCQoyPj49p37692bdvn5uqdZ3k5GQzbNgwU61aNePr62tuu+02M2bMGIcPNauMffXq1Tn+3+7Tp48xJnfj/OWXX0yvXr1MyZIlTenSpU2/fv1MSkqKG0bjnBuN/ciRI9f9vbd69Wr7Mori2G/2Pf+znMJNYR23zZhrbrUJAABQxHHODQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQCn2Gw2ffbZZ5Kko0ePymazaceOHbe0hnvuuUfPPvvsLV1nfly7zXKjb9++6tKlS4HVA1gdTwUHiom+ffvqwoULTn3I3kzVqlV1+vRpBQUFuWyZAJBfhBsAeebp6en2p/8CwJ9xWAoopu655x4NHTpUL7zwgsqVK6fQ0FC9/PLLDn0OHDigu+++W76+vqpbt65WrFjhMD2nw1I//fSTHn74YZUuXVqlSpVS27ZtdejQIfv0OXPmqE6dOvL19VXt2rX17rvv3rDO1NRURUdHq2TJkqpYsaLefPPNbH3S0tL0/PPPq3LlygoICFBERITWrFlzw+XabDb94x//0MMPPyx/f3/VqVNH69ev18GDB3XPPfcoICBAd911l0PtkjRr1izVqFFD3t7eqlWrlubPn+/UNpOk48eP6/HHH1eZMmVUrlw5PfLIIzp69Oh1a01LS9PQoUMVHBwsX19ftWnTRps3b77h+IDijHADFGMfffSRAgICtHHjRk2ZMkWvvvqq/cM4MzNTXbt2lbe3tzZu3KjZs2dr5MiRN1zeyZMndffdd8vHx0erVq3S1q1b1b9/f129elWSFB8fr3Hjxum1117T3r17NXHiRI0dO1YfffTRdZc5YsQIffvtt/rvf/+r//3vf1qzZo22bdvm0CcmJkbr16/XwoULtXPnTnXv3l0PPvigDhw4cMN6J0yYoOjoaO3YsUO1a9fWE088oaeeekqjR4/Wli1bZIxRTEyMvf+SJUs0bNgwPffcc9q9e7eeeuop9evXT6tXr871Nrty5YqioqJUqlQprVu3Tt9//71KliypBx98UOnp6TnW+cILL+g///mPPvroI23btk233367oqKidP78+RuODyi23PzgTgC3SJ8+fcwjjzxif9+uXTvTpk0bhz4tWrQwI0eONMYYs3z5clOiRAlz8uRJ+/Svv/7aSDJLliwxxhj7E5O3b99ujDFm9OjRJjw83KSnp+dYQ40aNcyCBQsc2iZMmGBatWqVY/+UlBTj7e1t/v3vf9vbfvnlF+Pn52d/IvuxY8eMp6enQ53GGNO+fXszevTonDeG+eMJ9y+99JL9/fr1640k88EHH9jbPv74Y+Pr62t/f9ddd5mBAwc6LKd79+6mQ4cOxpjcbbP58+ebWrVqmczMTHuftLQ04+fnZ5YvX26McfxeXbx40Xh5eZn4+Hh7//T0dFOpUiUzZcqU644PKM445wYoxho2bOjwvmLFikpKSpIk7d27V1WrVlWlSpXs01u1anXD5e3YsUNt27aVl5dXtmmpqak6dOiQBgwYoIEDB9rbr169qsDAwByXd+jQIaWnpysiIsLeVq5cOdWqVcv+fteuXcrIyNAdd9zhMG9aWprKly9/w3qvHX9ISIgkqUGDBg5tv//+u5KTk1W6dGnt3btXgwYNclhG69at9fbbb0vK3Tb78ccfdfDgQZUqVcqh/ffff892CCxrG1y5ckWtW7e2t3l5eally5bau3fvDccHFFeEG6AY+3MIsdlsyszMzPPy/Pz8rjvt4sWLkqT333/fIaxIf5yYnFcXL16Up6entm7dmm05JUuWvOG8147fZrNdty0/2+TPLl68qGbNmik+Pj7btAoVKrhsPUBxxjk3AHJUp04dHT9+XKdPn7a3bdiw4YbzNGzYUOvWrdOVK1eyTQsJCVGlSpV0+PBh3X777Q6v8PDwHJdXo0YNeXl5aePGjfa2X3/9Vfv377e/b9KkiTIyMpSUlJRtua6+kqtOnTr6/vvvHdq+//571a1b1z79ZtusadOmOnDggIKDg7PVm9MerKyTl69d75UrV7R582b7egE4ItwAyFFkZKTuuOMO9enTRz/++KPWrVunMWPG3HCemJgYJScnq2fPntqyZYsOHDig+fPna9++fZKkV155RXFxcZo+fbr279+vXbt2ad68eZo6dWqOyytZsqQGDBigESNGaNWqVdq9e7f69u0rD4///9V1xx13qHfv3oqOjtbixYt15MgRbdq0SXFxcVq6dKnrNoj+OLn5ww8/1KxZs3TgwAFNnTpVixcv1vPPPy8pd9usd+/eCgoK0iOPPKJ169bpyJEjWrNmjYYOHaoTJ05kW2dAQIAGDx6sESNGaNmyZdqzZ48GDhyoS5cuacCAAS4dH2AVhBsAOfLw8NCSJUt0+fJltWzZUn/961/12muv3XCe8uXLa9WqVbp48aLatWunZs2a6f3337cf6vnrX/+qOXPmaN68eWrQoIHatWunDz/88Lp7biTp9ddfV9u2bdWpUydFRkaqTZs2atasmUOfefPmKTo6Ws8995xq1aqlLl26aPPmzapWrVr+N8Q1unTporfffltvvPGG6tWrp3/84x+aN2+e7rnnHkm522b+/v5au3atqlWrpq5du6pOnToaMGCAfv/9d5UuXTrH9U6aNEndunXTk08+qaZNm+rgwYNavny5ypYt69LxAVZhM8YYdxcBAADgKuy5AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlvJ/Zo03slhXIoAAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "#Ahora loopeamos por los hiperparametros\n",
    "#2*2*2*3*3*2 = 144 modelos. Aproximadamente 15s por modelo, aprox 40 min para probar todos\n",
    "\n",
    "\n",
    "counter = 0\n",
    "list_acc = []\n",
    "list_opt = []\n",
    "for epoch in epoch_n: #\n",
    "    for batch in batch_size_n:#\n",
    "        for capas in layers_n: # \n",
    "            for neurons in neurons_n: #\n",
    "                for learning_r in learning_rates:\n",
    "                    for optimizador in optimizers: #\n",
    "                        model = keras.Sequential()\n",
    "\n",
    "                        model.add(layers.Input(shape=(784, )))\n",
    "                        for i in range(capas):\n",
    "                            model.add(layers.Dense(neurons, activation=\"relu\"))\n",
    "\n",
    "                        model.add(layers.Dense(10, activation=\"softmax\"))\n",
    "                        \n",
    "                        if optimizador ==\"rmsprop\":\n",
    "                            opt = keras.optimizers.RMSprop(learning_rate=learning_r)\n",
    "                        if optimizador ==\"Adam\":\n",
    "                            opt = keras.optimizers.Adam(learning_rate=learning_r)\n",
    "                        \n",
    "                        model.compile(optimizer=opt, \n",
    "                                  loss=\"categorical_crossentropy\",\n",
    "                                  metrics=[\"accuracy\"])\n",
    "\n",
    "                        history =model.fit(train_images, train_labels, epochs=epoch,verbose=0, batch_size=batch, \n",
    "                            validation_data = (validation_images, validation_labels))\n",
    "                        \n",
    "                        history_dict = history.history\n",
    "                        result_val = max(history_dict['val_accuracy'])\n",
    "                        print(\"Accuracy = \",result_val)\n",
    "                        \n",
    "#Guardamos todos los modelos  if result[0]< result_val:\n",
    "                        list_acc+=[result_val]\n",
    "                                  \n",
    "                        list_opt+= [\"epoch: \"+ str(epoch)+ \"\\n batch: \" +str(batch)+ \"\\n layers: \" +str(capas)+ \"\\n neurons: \" \n",
    "                                    +str(neurons)+ \"\\n learning rate: \" +str(learning_r) +\" optimizador: \" +optimizador]                     \n",
    "                        counter +=1\n",
    "                        print(\"counter:\",counter)     \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Mostramos los resultados de las accuracies obtenidas para cada modelo\n",
    "\n",
    "\n",
    "plt.bar(range(len(list_acc)), list_acc)\n",
    "\n",
    "plt.title('Accuracy de los modelos')\n",
    "plt.xlabel('Indice de modelo')\n",
    "plt.ylabel('Accuracy de modelo')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3a23d58b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top  5  model: Nº =  124 Accuracy =  0.8924000263214111 options: \n",
      " epoch: 30\n",
      " batch: 512\n",
      " layers: 1\n",
      " neurons: 128\n",
      " learning rate: 0.001 optimizador: rmsprop\n",
      "Top  4  model: Nº =  101 Accuracy =  0.8924999833106995 options: \n",
      " epoch: 30\n",
      " batch: 32\n",
      " layers: 2\n",
      " neurons: 64\n",
      " learning rate: 0.001 optimizador: Adam\n",
      "Top  3  model: Nº =  89 Accuracy =  0.8946999907493591 options: \n",
      " epoch: 30\n",
      " batch: 32\n",
      " layers: 1\n",
      " neurons: 128\n",
      " learning rate: 0.001 optimizador: Adam\n",
      "Top  2  model: Nº =  107 Accuracy =  0.8960000276565552 options: \n",
      " epoch: 30\n",
      " batch: 32\n",
      " layers: 2\n",
      " neurons: 128\n",
      " learning rate: 0.001 optimizador: Adam\n",
      "Top  1  model: Nº =  142 Accuracy =  0.8980000019073486 options: \n",
      " epoch: 30\n",
      " batch: 512\n",
      " layers: 2\n",
      " neurons: 128\n",
      " learning rate: 0.001 optimizador: rmsprop\n",
      "Bottom  5  model:Nº =  31 Accuracy =  0.10220000147819519 options: \n",
      "  epoch: 30\n",
      " batch: 512\n",
      " layers: 2\n",
      " neurons: 16\n",
      " learning rate: 0.1 optimizador: rmsprop\n",
      "Bottom  4  model:Nº =  31 Accuracy =  0.10220000147819519 options: \n",
      "  epoch: 30\n",
      " batch: 512\n",
      " layers: 2\n",
      " neurons: 64\n",
      " learning rate: 0.1 optimizador: rmsprop\n",
      "Bottom  3  model:Nº =  31 Accuracy =  0.10220000147819519 options: \n",
      "  epoch: 30\n",
      " batch: 512\n",
      " layers: 2\n",
      " neurons: 128\n",
      " learning rate: 0.1 optimizador: rmsprop\n",
      "Bottom  2  model:Nº =  31 Accuracy =  0.10220000147819519 options: \n",
      "  epoch: 10\n",
      " batch: 32\n",
      " layers: 1\n",
      " neurons: 16\n",
      " learning rate: 0.1 optimizador: rmsprop\n",
      "Bottom  1  model:Nº =  31 Accuracy =  0.10220000147819519 options: \n",
      "  epoch: 10\n",
      " batch: 32\n",
      " layers: 2\n",
      " neurons: 128\n",
      " learning rate: 0.1 optimizador: Adam\n"
     ]
    }
   ],
   "source": [
    "#Nos quedamos con los 5 mejores y peores modelos\n",
    "\n",
    "cut = 5\n",
    "\n",
    "bottom = sorted(range(len(list_acc)), key=lambda i: list_acc[i], reverse=True)[-cut:]\n",
    "top = sorted(range(len(list_acc)), key=lambda i: list_acc[i])[-cut:]\n",
    "\n",
    "\n",
    "\n",
    "for x in range(cut):\n",
    "    #print(\"Top \", cut-x, \" model: Accuracy = \", list_acc[top[x]], \"options: \", list_opt[top[x]])3\n",
    "    print(\"Top \", cut-x, \" model: Nº = \", top[x],\"Accuracy = \",list_acc[top[x]], \"options: \\n\", list_opt[top[x]])\n",
    "    \n",
    "for y in range(cut):  \n",
    "    #print(\"Bottom \", cut-y, \" model: Accuracy = \", list_acc[bottom[y]], \"options: \", list_opt[bottom[y]])\n",
    "    print(\"Bottom \", cut-y, \" model:Nº = \", bottom[x],\"Accuracy = \",list_acc[bottom[x]], \"options: \\n \", list_opt[bottom[y]])\n",
    "\n",
    "\n",
    "#plt.bar(range(len(list_acc)), list_acc)\n",
    "#plt.title('Accuracy de los modelos')\n",
    "#plt.xlabel('Indice de modelo')\n",
    "#plt.ylabel('Accuracy de modelo')\n",
    "#plt.legend()\n",
    "#plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4113448-f6a5-429e-89fa-9972b5f5d46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Top  5  model: Nº =  124 Accuracy =  0.8924000263214111 options: \n",
    " epoch: 30\n",
    " batch: 512\n",
    " layers: 1\n",
    " neurons: 128\n",
    " learning rate: 0.001 optimizador: rmsprop\n",
    "Top  4  model: Nº =  101 Accuracy =  0.8924999833106995 options: \n",
    " epoch: 30\n",
    " batch: 32\n",
    " layers: 2\n",
    " neurons: 64\n",
    " learning rate: 0.001 optimizador: Adam\n",
    "Top  3  model: Nº =  89 Accuracy =  0.8946999907493591 options: \n",
    " epoch: 30\n",
    " batch: 32\n",
    " layers: 1\n",
    " neurons: 128\n",
    " learning rate: 0.001 optimizador: Adam\n",
    "Top  2  model: Nº =  107 Accuracy =  0.8960000276565552 options: \n",
    " epoch: 30\n",
    " batch: 32\n",
    " layers: 2\n",
    " neurons: 128\n",
    " learning rate: 0.001 optimizador: Adam\n",
    "Top  1  model: Nº =  142 Accuracy =  0.8980000019073486 options: \n",
    " epoch: 30\n",
    " batch: 512\n",
    " layers: 2\n",
    " neurons: 128\n",
    " learning rate: 0.001 optimizador: rmsprop\n",
    "Bottom  5  model:Nº =  31 Accuracy =  0.10220000147819519 options: \n",
    "  epoch: 30\n",
    " batch: 512\n",
    " layers: 2\n",
    " neurons: 16\n",
    " learning rate: 0.1 optimizador: rmsprop\n",
    "Bottom  4  model:Nº =  31 Accuracy =  0.10220000147819519 options: \n",
    "  epoch: 30\n",
    " batch: 512\n",
    " layers: 2\n",
    " neurons: 64\n",
    " learning rate: 0.1 optimizador: rmsprop\n",
    "Bottom  3  model:Nº =  31 Accuracy =  0.10220000147819519 options: \n",
    "  epoch: 30\n",
    " batch: 512\n",
    " layers: 2\n",
    " neurons: 128\n",
    " learning rate: 0.1 optimizador: rmsprop\n",
    "Bottom  2  model:Nº =  31 Accuracy =  0.10220000147819519 options: \n",
    "  epoch: 10\n",
    " batch: 32\n",
    " layers: 1\n",
    " neurons: 16\n",
    " learning rate: 0.1 optimizador: rmsprop\n",
    "Bottom  1  model:Nº =  31 Accuracy =  0.10220000147819519 options: \n",
    "  epoch: 10\n",
    " batch: 32\n",
    " layers: 2\n",
    " neurons: 128\n",
    " learning rate: 0.1 optimizador: Adam\n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e91c4c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "118/118 [==============================] - 1s 3ms/step - loss: 0.7391 - accuracy: 0.7405\n",
      "Epoch 2/30\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 0.4870 - accuracy: 0.8251\n",
      "Epoch 3/30\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 0.4282 - accuracy: 0.8454\n",
      "Epoch 4/30\n",
      "118/118 [==============================] - 1s 10ms/step - loss: 0.3930 - accuracy: 0.8549\n",
      "Epoch 5/30\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.3659 - accuracy: 0.8662\n",
      "Epoch 6/30\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.3478 - accuracy: 0.8715\n",
      "Epoch 7/30\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 0.3317 - accuracy: 0.8779\n",
      "Epoch 8/30\n",
      "118/118 [==============================] - 1s 8ms/step - loss: 0.3205 - accuracy: 0.8826\n",
      "Epoch 9/30\n",
      "118/118 [==============================] - 1s 10ms/step - loss: 0.3076 - accuracy: 0.8867\n",
      "Epoch 10/30\n",
      "118/118 [==============================] - 1s 12ms/step - loss: 0.2959 - accuracy: 0.8892\n",
      "Epoch 11/30\n",
      "118/118 [==============================] - 1s 4ms/step - loss: 0.2863 - accuracy: 0.8940\n",
      "Epoch 12/30\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 0.2795 - accuracy: 0.8948\n",
      "Epoch 13/30\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 0.2712 - accuracy: 0.8988\n",
      "Epoch 14/30\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 0.2644 - accuracy: 0.9002\n",
      "Epoch 15/30\n",
      "118/118 [==============================] - 1s 12ms/step - loss: 0.2569 - accuracy: 0.9042\n",
      "Epoch 16/30\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 0.2517 - accuracy: 0.9070\n",
      "Epoch 17/30\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.2456 - accuracy: 0.9080\n",
      "Epoch 18/30\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 0.2384 - accuracy: 0.9109\n",
      "Epoch 19/30\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 0.2345 - accuracy: 0.9116\n",
      "Epoch 20/30\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.2273 - accuracy: 0.9145\n",
      "Epoch 21/30\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 0.2218 - accuracy: 0.9154\n",
      "Epoch 22/30\n",
      "118/118 [==============================] - 1s 9ms/step - loss: 0.2177 - accuracy: 0.9186\n",
      "Epoch 23/30\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.2128 - accuracy: 0.9197\n",
      "Epoch 24/30\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.2089 - accuracy: 0.9208\n",
      "Epoch 25/30\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.2034 - accuracy: 0.9230\n",
      "Epoch 26/30\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.1996 - accuracy: 0.9241\n",
      "Epoch 27/30\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.1963 - accuracy: 0.9253\n",
      "Epoch 28/30\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.1918 - accuracy: 0.9279\n",
      "Epoch 29/30\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.1894 - accuracy: 0.9295\n",
      "Epoch 30/30\n",
      "118/118 [==============================] - 1s 4ms/step - loss: 0.1849 - accuracy: 0.9309\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.4149 - accuracy: 0.8662\n",
      "[0.4149317741394043, 0.8661999702453613]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#Ahora ejecutamos el modelo sobre los datos de test para ver su accuracy real\n",
    "best_model = keras.Sequential()\n",
    "\n",
    "best_model.add(layers.Input(shape=(784, )))\n",
    "for i in range(2):\n",
    "    best_model.add(layers.Dense(128, activation=\"relu\"))\n",
    "best_model.add(layers.Dense(10, activation=\"softmax\"))\n",
    "opt = keras.optimizers.RMSprop(learning_rate=0.001)                        \n",
    "                        \n",
    "best_model.compile(optimizer=opt, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "best_model.fit(final_training_images, final_training_labels, epochs=30,verbose=1, batch_size=512)\n",
    "#TODO Definir el modelo que mejor resultado de y reentrenarlo\n",
    "\n",
    "results = best_model.evaluate(test_images, test_labels)\n",
    "\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f052cf98-b18a-4fc3-867f-db919108a2dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[89, 35, 107, 125, 142]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f5d918b8",
   "metadata": {},
   "source": [
    "# REGULARIZACIÓN\n",
    "Ahora vamos a probar algunos de los modelos anteriores utilizando las técnicas de regularización de \"dropout\" y \"batch normalization\" para tratar de obtener mejores resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1c1299",
   "metadata": {},
   "source": [
    "## Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7269ada1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "118/118 [==============================] - 3s 17ms/step - loss: 0.8086 - accuracy: 0.7178\n",
      "Epoch 2/30\n",
      "118/118 [==============================] - 2s 18ms/step - loss: 0.5162 - accuracy: 0.8148\n",
      "Epoch 3/30\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 0.4527 - accuracy: 0.8357\n",
      "Epoch 4/30\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.4138 - accuracy: 0.8487\n",
      "Epoch 5/30\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.3911 - accuracy: 0.8569\n",
      "Epoch 6/30\n",
      "118/118 [==============================] - 1s 10ms/step - loss: 0.3723 - accuracy: 0.8637\n",
      "Epoch 7/30\n",
      "118/118 [==============================] - 1s 8ms/step - loss: 0.3611 - accuracy: 0.8686\n",
      "Epoch 8/30\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.3468 - accuracy: 0.8727\n",
      "Epoch 9/30\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.3370 - accuracy: 0.8759\n",
      "Epoch 10/30\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.3276 - accuracy: 0.8790\n",
      "Epoch 11/30\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.3199 - accuracy: 0.8826\n",
      "Epoch 12/30\n",
      "118/118 [==============================] - 2s 16ms/step - loss: 0.3140 - accuracy: 0.8832\n",
      "Epoch 13/30\n",
      "118/118 [==============================] - 2s 18ms/step - loss: 0.3064 - accuracy: 0.8870\n",
      "Epoch 14/30\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 0.3012 - accuracy: 0.8874\n",
      "Epoch 15/30\n",
      "118/118 [==============================] - 1s 11ms/step - loss: 0.2964 - accuracy: 0.8903\n",
      "Epoch 16/30\n",
      "118/118 [==============================] - 2s 18ms/step - loss: 0.2897 - accuracy: 0.8922\n",
      "Epoch 17/30\n",
      "118/118 [==============================] - 2s 15ms/step - loss: 0.2873 - accuracy: 0.8932\n",
      "Epoch 18/30\n",
      "118/118 [==============================] - 1s 4ms/step - loss: 0.2833 - accuracy: 0.8942\n",
      "Epoch 19/30\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.2750 - accuracy: 0.8975\n",
      "Epoch 20/30\n",
      "118/118 [==============================] - 1s 8ms/step - loss: 0.2727 - accuracy: 0.8992\n",
      "Epoch 21/30\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 0.2680 - accuracy: 0.8995\n",
      "Epoch 22/30\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 0.2681 - accuracy: 0.9009\n",
      "Epoch 23/30\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 0.2621 - accuracy: 0.9014\n",
      "Epoch 24/30\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.2584 - accuracy: 0.9026\n",
      "Epoch 25/30\n",
      "118/118 [==============================] - 1s 9ms/step - loss: 0.2574 - accuracy: 0.9037\n",
      "Epoch 26/30\n",
      "118/118 [==============================] - 1s 4ms/step - loss: 0.2525 - accuracy: 0.9042\n",
      "Epoch 27/30\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.2484 - accuracy: 0.9056\n",
      "Epoch 28/30\n",
      "118/118 [==============================] - 1s 8ms/step - loss: 0.2458 - accuracy: 0.9074\n",
      "Epoch 29/30\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.2436 - accuracy: 0.9076\n",
      "Epoch 30/30\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 0.2413 - accuracy: 0.9102\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x216c40317d0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dropout\n",
    "#Vamos a probar a añadir a este modelo dropout.\n",
    "#Definir modelo y para implementar el dropout, añadir las capas de Dropout\n",
    "\n",
    "best_model = keras.Sequential()\n",
    "\n",
    "best_model.add(layers.Input(shape=(784, )))\n",
    "for i in range(2):\n",
    "    best_model.add(layers.Dense(128, activation=\"relu\"))\n",
    "    best_model.add(layers.Dropout(0.2))\n",
    "best_model.add(layers.Dense(10, activation=\"softmax\"))\n",
    "opt = keras.optimizers.RMSprop(learning_rate=0.001)                        \n",
    "                        \n",
    "best_model.compile(optimizer=opt, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "best_model.fit(final_training_images, final_training_labels, epochs=30,verbose=1, batch_size=512)\n",
    "\n",
    "\n",
    "results = best_model.evaluate(test_images, test_labels)\n",
    "\n",
    "print(results)\n",
    "\n",
    "#Ejecutar 3 o 4 modelos entre los que esté el mejor obtenido anteriormente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "caa45b28-94a3-420a-bd8a-462536d78e46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 957us/step - loss: 0.3932 - accuracy: 0.8686\n",
      "[0.39316168427467346, 0.8686000108718872]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "593dbe0e",
   "metadata": {},
   "source": [
    "### Resultados del dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2393e53",
   "metadata": {},
   "source": [
    "## Batch normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "747da55c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 0.4999 - accuracy: 0.8231\n",
      "Epoch 2/30\n",
      "118/118 [==============================] - 2s 13ms/step - loss: 0.3527 - accuracy: 0.8718\n",
      "Epoch 3/30\n",
      "118/118 [==============================] - 2s 17ms/step - loss: 0.3145 - accuracy: 0.8849\n",
      "Epoch 4/30\n",
      "118/118 [==============================] - 1s 12ms/step - loss: 0.2909 - accuracy: 0.8933\n",
      "Epoch 5/30\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.2731 - accuracy: 0.8990\n",
      "Epoch 6/30\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 0.2582 - accuracy: 0.9045\n",
      "Epoch 7/30\n",
      "118/118 [==============================] - 1s 11ms/step - loss: 0.2436 - accuracy: 0.9096\n",
      "Epoch 8/30\n",
      "118/118 [==============================] - 2s 15ms/step - loss: 0.2326 - accuracy: 0.9135\n",
      "Epoch 9/30\n",
      "118/118 [==============================] - 2s 16ms/step - loss: 0.2194 - accuracy: 0.9188\n",
      "Epoch 10/30\n",
      "118/118 [==============================] - 2s 17ms/step - loss: 0.2098 - accuracy: 0.9217\n",
      "Epoch 11/30\n",
      "118/118 [==============================] - 2s 17ms/step - loss: 0.2010 - accuracy: 0.9262\n",
      "Epoch 12/30\n",
      "118/118 [==============================] - 1s 9ms/step - loss: 0.1932 - accuracy: 0.9279\n",
      "Epoch 13/30\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.1866 - accuracy: 0.9313\n",
      "Epoch 14/30\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 0.1783 - accuracy: 0.9340\n",
      "Epoch 15/30\n",
      "118/118 [==============================] - 1s 11ms/step - loss: 0.1711 - accuracy: 0.9351\n",
      "Epoch 16/30\n",
      "118/118 [==============================] - 2s 19ms/step - loss: 0.1645 - accuracy: 0.9396\n",
      "Epoch 17/30\n",
      "118/118 [==============================] - 2s 18ms/step - loss: 0.1575 - accuracy: 0.9420\n",
      "Epoch 18/30\n",
      "118/118 [==============================] - 2s 15ms/step - loss: 0.1514 - accuracy: 0.9439\n",
      "Epoch 19/30\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.1478 - accuracy: 0.9451\n",
      "Epoch 20/30\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 0.1419 - accuracy: 0.9474\n",
      "Epoch 21/30\n",
      "118/118 [==============================] - 1s 12ms/step - loss: 0.1369 - accuracy: 0.9499\n",
      "Epoch 22/30\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 0.1292 - accuracy: 0.9517\n",
      "Epoch 23/30\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 0.1280 - accuracy: 0.9522\n",
      "Epoch 24/30\n",
      "118/118 [==============================] - 2s 18ms/step - loss: 0.1241 - accuracy: 0.9542\n",
      "Epoch 25/30\n",
      "118/118 [==============================] - 2s 18ms/step - loss: 0.1225 - accuracy: 0.9553\n",
      "Epoch 26/30\n",
      "118/118 [==============================] - 2s 18ms/step - loss: 0.1188 - accuracy: 0.9557\n",
      "Epoch 27/30\n",
      "118/118 [==============================] - 2s 18ms/step - loss: 0.1141 - accuracy: 0.9586\n",
      "Epoch 28/30\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 0.1093 - accuracy: 0.9600\n",
      "Epoch 29/30\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.1067 - accuracy: 0.9612\n",
      "Epoch 30/30\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.1002 - accuracy: 0.9639\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.4726 - accuracy: 0.8685\n",
      "[0.4726162552833557, 0.8684999942779541]\n"
     ]
    }
   ],
   "source": [
    "#batch normalization\n",
    "\n",
    "#Similarmente al caso anterior, implementamos la batch regularization añadiendo capas intermedias de regularización\n",
    "\n",
    "\n",
    "best_model = keras.Sequential()\n",
    "\n",
    "best_model.add(layers.Input(shape=(784, )))\n",
    "for i in range(2):\n",
    "    best_model.add(layers.Dense(128, activation=\"relu\"))\n",
    "    best_model.add(layers.BatchNormalization())\n",
    "best_model.add(layers.Dense(10, activation=\"softmax\"))\n",
    "opt = keras.optimizers.RMSprop(learning_rate=0.001)                        \n",
    "                        \n",
    "best_model.compile(optimizer=opt, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "best_model.fit(final_training_images, final_training_labels, epochs=30,verbose=1, batch_size=512)\n",
    "\n",
    "\n",
    "results = best_model.evaluate(test_images, test_labels)\n",
    "\n",
    "print(results)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Ejecutar 3 o 4 modelos entre los que esté el mejor obtenido anteriormente"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9d4a02",
   "metadata": {},
   "source": [
    "### Resultados de la batch normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72828e4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
